[
["timeseries.html", "Chapter 2 Introduction to Time Series Analysis 2.1 Time Series 2.2 Dependence within Time Series 2.3 Stationarity 2.4 Linear Processes 2.5 Basic Time Series Models 2.6 Fundamental Representations of Time Series 2.7 Estimation Problems with Time Series", " Chapter 2 Introduction to Time Series Analysis In this chapter we give an introduction to time series analysis. For this purpose, it is organized in the following order: Definition and descriptive analysis of time series; Dependence within time series (and fundamental representations); Stationarity of time series; Basic time series models; Linear processes; Latent (or composite) stochastic processes; Estimation problems with time series. 2.1 Time Series Definition 2.1 (Time Series) A time series is a stochastic process (i.e. a sequence of random variables) defined on a common probability space. Let us denote this time-indexed stochastic process (time series) as \\((X_t)_{t = 1,...,T}\\), i.e. (\\(X_1\\), \\(X_2\\), …., \\(X_T\\)), where the time \\(t\\) belongs to the discrete index set. Therefore, we implicitly assume that \\(t\\) is non-random, i.e. the time at which each observation is measured is known, and the time between two consecutive observations is constant (i.e. sampling occurs at regular intervals). As for any data analysis procedure, the first step consists in representing the data in such a way as to highlight any important features or information that should be taken into account for the following statistical analysis. For time series, a typical first step is representing the observations over time (where the latter is represented on the x-axis and values of \\(X_t\\) on the y-axis). This can be considered as the first step for the descriptive analysis of a time series, especially when their length is moderate. With this in mind, when performing a descriptive analysis of a time series it is customary to check the following aspects: Trends Seasonal (e.g. business cycles) Non-seasonal (e.g. impact of economic indicators on stock returns) Local fluctuations (e.g. vibrations observed before, during and after an earthquake) Changes in the statistical properties Mean (e.g. economic crisis) Variance (e.g. earnings) States (e.g. bear/bull in finance) Model deviations (e.g. outliers) In order to give an idea of what the above characteristics imply for a time series, the following examples provide practical insight for some of them. Example 2.1 (Johnson and Johnson Quarterly Earnings) A first example of a time series is the quarterly earnings of the company Johnson and Johnson. In the graph below, we present these earnings between 1960 and 1980. # Load simts package library(simts) # Load data data(jj, package = &quot;astsa&quot;) # Construct gts object jj = gts(jj, start = 1960, freq = 4) # Plot time series plot(jj, main = &quot;Johnson and Johnson Quarterly Earnings&quot;, xlab = &quot;Time (year)&quot;, ylab = &quot;Quarterly Earnings per Share ($)&quot;) Figure 2.1: Johnson and Johnson Quarterly Earnings As we can see from the plot, the data contains a non-linear increasing trend as well as a seasonal component highlighted by the almost regularly-spaced peaks and valleys along time. In addition, we can notice that the variability of the data seems to increase with time (the seasonal variations appear to be larger towards the end of the plot). Hence, this simple visual representation can deliver important insight as to the behaviour of the time series and consequently determine the steps to take for further analysis (e.g. consider a non-linear model to explain the trend and consider approaches to model changing variance). \\(\\LARGE{\\bullet}\\) Example 2.2 (Monthly Precipitation Data) Let us consider another data set coming from the domain of hydrology. The data records monthly precipitation (in mm) over a certain period of time (1907 to 1972) and is interesting for hydrologists for the purpose of studying water cycles. The data are presented in the plot below: # Load data data(hydro, package = &quot;simts&quot;) # Construct gts object hydro = gts(hydro, start = 1907, freq = 12) # Plot time series plot(hydro, main = &quot;Monthly Precipitation Data&quot;, xlab = &quot;Time (year)&quot;, ylab = &quot;Mean Monthly Precipitation (mm)&quot;) Figure 2.2: Monthly Precipitation Data The time series plot above differs considerably from the previous one since the values of the time series, being always non-negative, remain almost always between 0 and 1 (no apparent trend) and randomly shows some larger observations that go beyond the value of 2 (or even 3). The latter appear to be extreme observations which could qualify as outliers, i.e. observations that are not representative of the true underlying model that generates the time series and can considerably affect the statistical analysis if not dealt with. \\(\\LARGE{\\bullet}\\) Example 2.3 (Inertial Sensor Data) Another example is provided by the data coming from the calibration procedure of an Inertial Measurement Unit (IMU). The signals (or time series) coming from an IMU are usually measured at high frequencies over a long time and are often characterized by linear trends and numerous underlying stochastic processes. The plot below represents the time series of an error signal coming from a gyroscope belonging to an IMU. # Load data data(imu6, package = &quot;imudata&quot;) # Construct gts object imu = gts(imu6[,1], freq = 100*60*60) # Plot time series plot(imu, main = &quot;Inertial Sensor Data&quot;, ylab = expression(paste(&quot;Angular Velocity &quot;, (rad/s))), xlab = &quot;Time (h)&quot;) Figure 2.3: Inertial Sensor Data As we can see from the plot, there wouldn’t appear to be any linear trend, seasonality or increased variation in the time series. Indeed, from this plot it is difficult to detect any particular characteristic of this time series although a linear trend and other processes are present in this data. Therefore, especially when the length of the time series is considerable, this representation of time series can only give insight into few aspects (if none) and consequently is not suitable, on its own, to adequately inform the subsequent statistical analysis. \\(\\LARGE{\\bullet}\\) In order to deliver a more appropriate (or more complete) representation of a time series, it is important to study the concept of dependence since (in a linear vision of time) past observations have an influence on present and (possibly) future ones. Hence, the next section gives an overview of this concept. 2.2 Dependence within Time Series As mentioned above, it is straightforward to assume that observations measured through time are dependent on each other (in that observations at time \\(t\\) have some form of impact on observations at time \\(t+1\\) or beyond). Due to this characteristic, one of the main interests in time series is prediction where, if \\((X_t)_{t=1,\\ldots,T}\\) is an identically distributed but not independent sequence, we often want to know the value of \\({X}_{T+h}\\) for \\(h &gt; 0\\) (i.e. an estimator of \\(\\mathbb{E}[X_{T+h}| X_T,...]\\)). In order to tackle this challenge, we first need to understand the dependence between \\(X_{1},\\ldots,X_{T}\\) and, even before this, we have to formally define what independence is. Definition 2.2 (Independence of Events) Two events \\(A\\) and \\(B\\) are independent if \\[\\begin{align*} \\mathbb{P}(A \\cap B) = \\mathbb{P}(A)\\mathbb{P}(B), \\end{align*}\\] with \\(\\mathbb{P}(A)\\) denoting the probability of event \\(A\\) occuring and \\(\\mathbb{P}(A \\cap B)\\) denoting the joint probability (i.e. the probability that events \\(A\\) and \\(B\\) occur jointly). In general, \\(A_{1},\\ldots,A_{n}\\) are independent if \\[\\begin{align*} \\mathbb{P}(A_1 \\ldots A_n) = \\mathbb{P}(A_1) \\ldots \\mathbb{P}(A_n) \\;\\; \\forall \\; A_i \\in S, \\;\\; i=1,\\ldots,n \\end{align*}\\] where \\(S\\) is the sample space. Definition 2.3 (Independence of Random Variables) Two random variables \\(X\\) and \\(Y\\) with Cumulative Distribution Functions (CDF) \\(F_X(x)\\) and \\(F_Y(y)\\), respectively, are independent if and only if their joint CDF \\(F_{X,Y}(x,y)\\) is such that \\[\\begin{align*} F_{X,Y}(x,y) = F_{X}(x) F_{Y}(y). \\end{align*}\\] In general, random variables \\(X_1, \\ldots, X_n\\) with CDF \\(F_{X_1}(x_1), \\ldots, F_{X_n}(x_n)\\) are respectively independent if and only if their joint CDF \\(F_{X_1, \\ldots, X_n}(x_1, \\ldots, x_n)\\) is such that \\[\\begin{align*} F_{X_1,\\ldots,X_n}(x_1,\\ldots,x_n) = F_{X_1}(x_1) \\ldots F_{X_n}(x_n). \\end{align*}\\] Definition 2.4 (iid sequence) The sequence \\(X_{1},X_{2},\\ldots,X_{T}\\) is said to be independent and identically distributed (i.e. iid) if and only if \\[\\begin{align*} \\mathbb{P}(X_{i}&lt;x) = \\mathbb{P}(X_{j}&lt;x) \\;\\; \\forall x \\in \\mathbb{R}, \\forall i,j \\in \\{1,\\ldots,T\\}, \\end{align*}\\] and \\[\\begin{align*} \\mathbb{P}(X_{1}&lt;x_{1},X_{2}&lt;x_{2},\\ldots,X_{T}&lt;x_{T})=\\mathbb{P}(X_{1}&lt;x_1) \\ldots \\mathbb{P}(X_{T}&lt;x_T) \\;\\; \\forall T\\geq2, x_1, \\ldots, x_T \\in \\mathbb{R}. \\end{align*}\\] The basic idea behind the above definitions of independence is the fact that the probability of an event regarding variable \\(X_i\\) remains unaltered no matter what occurs for variable \\(X_j\\) (for \\(i \\neq j\\)). From this definition, we can now start exploring the concept of dependence, starting from linear dependence within a time series. For this purpose, below we define a quantity called AutoCovariance (ACV). Definition 2.5 (AutoCovariance) Autocovariance denoted as \\(\\gamma_X(t, t+h)\\) is defined as \\[\\begin{align*} \\gamma_X(t, t+h) = \\text{Cov}(X_{t},X_{t+h})= \\mathbb{E}(X_{t}X_{t+h})-\\mathbb{E}(X_{t})\\mathbb{E}(X_{t+h}), \\end{align*}\\] where \\(\\text{Cov}(\\cdot)\\) denotes the covariance and \\[\\begin{align*} \\mathbb{E}(X_{t}) = \\int_{-\\infty}^{\\infty}x \\, f(x) \\, dx \\;\\; \\text{and} \\;\\; \\mathbb{E}(X_{t},X_{t+h}) = \\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty}x_{t}\\,x_{t+h}\\, f(x_{t},x_{t+h}) \\, dx_{t}\\,dx_{t+h}, \\end{align*}\\] where \\(f(x)\\) denotes the density of \\(X_t\\) and \\(f(x_{t},x_{t+h})\\) denotes the joint density of \\(X_{t}\\) and \\(X_{t+h}\\). Notice that, when two variable are independent, \\(\\mathbb{E}(X_{t}X_{t+h}) = \\mathbb{E}(X_{t})\\mathbb{E}(X_{t+h})\\) and hence \\(\\gamma_X(t, t+h) = 0\\). In a nutshell, the ACV measures the degree to which the mean-behaviour of a variable (e.g. \\(X_{t+h}\\)) changes when another one changes (e.g. \\(X_t\\)) and hence, to what extent they are linearly dependent. Remark 2.1 (Properties of ACV) ACV is symmetric, i.e. \\(\\gamma_X(t, t+h) = \\gamma_X(t+h, t)\\) as \\(\\text{Cov}(X_{t},X_{t+h}) = \\text{Cov}(X_{t+h},X_{t})\\). Under stationarity (will be discussed very soon, see Section 2.3 for more details), \\(\\gamma_X(h) = \\gamma_X(-h)\\), i.e. ACV is an even function. Variance of the process \\(\\text{Var}(X_t) = \\gamma_X(t, t) \\geq 0\\). Under stationarity, \\(\\text{Var}(X_t) = \\gamma_X(0)\\) and \\(\\mid \\gamma_X(h) \\mid \\leq \\gamma_X(0)\\) by Cauchy-Schwarz inequality. Scale dependent: ACV \\(\\gamma_X(t, t+h)\\) is scale dependent like any covariance. So \\(\\gamma_X(t, t+h) \\in \\mathbb{R}\\). If \\(\\mid \\gamma_X(t, t+h) \\mid\\) is “close” to 0, then \\(X_{t}\\) and \\(X_{t+h}\\) are “less (linearly) dependent”. If \\(\\mid \\gamma_X(t, t+h) \\mid\\) is “far” from 0, then \\(X_{t}\\) and \\(X_{t+h}\\) are “more (linearly) dependent”. However in general, it is difficult to assess what “close” and “far” from zero mean. In general, \\(\\gamma_X(t, t+h)=0\\) does not imply \\(X_{t}\\) and \\(X_{t+h}\\) are independent. However, if \\(X_{t}\\) and \\(X_{t+h}\\) are joint normally distributed, then \\(\\gamma_X(t, t+h)=0\\) implies that \\(X_{t}\\) and \\(X_{t+h}\\) are independent. However the ACV is a quantity whose bounds are not known a priori and it can consequently be impossible to determine whether the degree of linear dependence is large or not. For this reason another measure of linear dependence can be used which is related to the ACV. Indeed, the AutoCorrelation Function (ACF) is a commonly used metric in time series analysis and is defined below. Definition 2.6 (AutoCorrelation) AutoCorrelation (ACF) denoted as \\(\\rho_X(t, t+h)\\) is defined as \\[\\begin{align*} \\rho_X(t,t+h) = \\text{Corr}(X_{t},X_{t+h}) = \\frac{\\text{Cov}(X_{t},X_{t+h})}{\\sqrt{\\text{Var}(X_{t})} \\sqrt{\\text{Var}(X_{t+h})}}, \\end{align*}\\] where \\(\\text{Var}(\\cdot)\\) denotes the variance. Remark 2.2 (Properties of ACF) \\(\\mid \\rho_X(t,t+h) \\mid \\leq 1\\) and \\(\\mid \\rho_X(t,t) \\mid = 1\\). ACF is symmetric, i.e. \\(\\rho_X(t, t+h) = \\rho_X(t+h, t)\\) as \\(\\text{Corr}(X_{t},X_{t+h}) = \\text{Corr}(X_{t+h},X_{t})\\). Under stationarity, \\(\\gamma_X(h) = \\gamma_X(-h)\\), i.e. ACF is an even function. Scale invariant: ACF \\(\\rho_X(t,t+h)\\) is scale free like any correlation. Moreover, if \\(\\rho_X(t,t+h)\\) is “close” to \\(\\pm 1\\), then this implies that there is “strong” (linear) dependence between \\(X_{t}\\) and \\(X_{t+h}\\). Since the ACV is bounded by the product of the standard deviations of the two variables, we have that the ACF is bounded between 1 and -1. Therefore it is possible to better interpret the linear dependence where an ACF of zero indicates an absence of linear dependence while an ACF close to 1 or -1 indicates respectively a strong positive or negative linear dependence. As underlined up to now, both ACV and ACF are appropriate to measure linear dependence only. Therefore if the ACV and ACF are both zero, this does not imply that there isn’t dependence between the variables. Indeed, aside from linear dependence, other forms of dependence such as monotonic or nonlinear dependence also exist which the ACV or ACF don’t measure directly. The figure below shows scatterplots (one variable on the x-axis and another on the y-axis) along with the values of the ACF: Figure 2.4: Different forms of dependence and their ACF values As can be seen, the first row in the figure shows a consistent behaviour of the ACF value since the absolute value goes closer to 1 the more the points go closer to forming a line. However, the following rows show plots where there is clearly a strong relation (dependence) between the variables but the ACF doesn’t detect this characteristic since this relation is not linear. Finally, it is worth noting that correlation does NOT imply causation. For example, if \\(\\rho(t, t+h) \\neq 0\\), this does not imply that \\(X_t \\to X_{t+h}\\) is causal. More specifically, the presence (or absence) of causality cannot be detected through statistical tools although some approximated metrics have been proposed to measure this concept (e.g Granger causality, see Granger 1969). For the following sections we will simplify the notations \\(\\gamma_X(t, t+h)\\) and \\(\\rho_X(t, t+h)\\) to be \\(\\gamma(h)\\) and \\(\\rho(h)\\) when there is no ambiguity (i.e. only one time series is considered and the ACF only depends on the time-lag \\(h\\)). 2.3 Stationarity In this section we are going to introduce the concept of stationarity, one of the most important characteristics of time series data. First let us consider an example of non-stationary processes. Example 2.4 (Non-Stationary Process) \\[\\begin{equation*} X_t \\sim \\mathcal{N} \\left(0, Y_t^2\\right) \\;\\; \\text{where $Y_t$ is unobserved and such that} \\;\\; Y_t \\overset{iid}{\\sim} \\mathcal{N} \\left(0, 1\\right). \\end{equation*}\\] In this case, it is clear that the estimation of \\(\\text{Var}(X_t)\\) is difficult since only \\(X_t\\) is useful for the estimation. So in fact, \\(X_t^2\\) is our best guess for \\(\\text{Var}(X_t)\\). \\(\\LARGE{\\bullet}\\) On the other hand, let us consider an example of stationary processes where averaging becomes meaningful for such process. Example 2.5 (Stationary Process) \\[\\begin{equation*} X_t = \\theta W_{t-1} + W_t \\;\\;\\; \\text{where} \\;\\;\\; W_t \\stackrel{iid}{\\sim} \\mathcal{N} \\left(0, 1\\right). \\end{equation*}\\] In this case, we can guess that a natural estimator of \\(\\text{Var}(X_t)\\) can be \\(\\hat{\\sigma}^2 = \\frac{1}{T} \\sum_{i = 1}^T X_i^2\\). That is, now averages are meaningful for such process. \\(\\LARGE{\\bullet}\\) We formalize the above idea by introducing the concept of stationarity. There exist two forms of stationarity, which are defined below: Definition 2.7 (Strong Stationarity) The time series \\(X_{t}\\) is strongly stationary if the joint probability distribution is invariant under a shift in time, i.e. \\[\\begin{equation*} \\mathbb{P}(X_{t}\\leq x_{0},\\ldots,X_{t+k}\\leq x_{k}) = \\mathbb{P}(X_{t+h}\\leq x_{0} ,\\ldots,X_{t+h+k}\\leq x_{k}) \\end{equation*}\\] for any time shift \\(h\\) and any \\(x_{0}, x_{1},x_{2},\\cdots,x_{k}\\) belong to the domain of \\(X_t,\\cdots,X_{t+k}\\) and \\(X_{t+h},\\cdots,X_{t+h+k}\\). Definition 2.8 (Weak Stationarity) The time series \\((X_{t})_{t \\in \\mathbb{N}}\\) is weakly stationary if the mean and autocovariance are finite and invariant under a shift in time, i.e. \\[\\begin{equation*} \\begin{aligned} \\mathbb{E}\\left[X_t\\right] &amp;= \\mu &lt; \\infty,\\\\ \\mathbb{E}\\left[X_t^2\\right] &amp;= \\mu_2 &lt; \\infty,\\\\ \\text{Cov}(X_{t},X_{t+h})&amp;= \\text{Cov}(X_{t + k},X_{t+h + k}) = \\gamma( h ). \\end{aligned} \\end{equation*}\\] for any time shift \\(h\\). For convenience, we use the abbreviation “stationary” to indicate “weakly stationary” by default. The stationarity of \\(X_{t}\\) is important because it provides a framework in which averaging makes sense. The concept of averaging is essentially meaningless unless properties like mean and covariance are either fixed or evolve in a known manner. Remark 2.3 (Implication on the ACV and ACF) If a process is weakly stationary or strongly stationary and \\(\\text{Cov}(X_{t},X_{t+h})\\) exists for all \\(h \\in \\mathbb{Z}\\), then we have both ACV and ACF only depend on the lag between observations, i.e. \\[\\begin{equation*} \\begin{aligned} \\gamma(t, t+h) &amp;= \\text{Cov}(X_{t},X_{t+h})= \\text{Cov}(X_{t + k},X_{t+h + k}) = \\gamma(t+k, t+h+k) = \\gamma(h),\\\\ \\rho(t, t+h) &amp;= \\text{Corr}(X_{t},X_{t+h})= \\text{Corr}(X_{t + k},X_{t+h + k}) = \\rho(t+k, t+h+k) = \\rho(h). \\end{aligned} \\end{equation*}\\] Remark 2.4 (Relation between Strong and Weak Stationarity) In general, neither type of stationarity implies the other one. However, If \\(X_{t}\\) is Normal (Gaussian) with \\(\\sigma^2 = \\text{Var} (X_{t}) &lt; \\infty\\), then weak stationarity implies strong stationarity. If \\(X_{t}\\) is strongly stationary, \\(\\mathbb{E}(X_t) &lt; \\infty\\) and \\(\\mathbb{E}(X_t^2) &lt; \\infty\\), then \\(X_{t}\\) is weakly stationary. Example 2.6 (Strong Stationarity does NOT imply Weak Stationarity) An iid Cauchy process is strongly but not weakly stationary as the mean of the process does not exist. \\(\\LARGE{\\bullet}\\) Example 2.7 (Weak Stationarity does NOT imply Strong Stationarity) Let \\(X_t \\overset{iid}{\\sim} \\exp(1)\\) (i.e. exponential distribution with \\(\\lambda = 1\\)) and \\(Y_t \\overset{iid}{\\sim} \\mathcal{N}(1,1)\\). Then, let \\[\\begin{equation*} Z_t = \\left\\{ \\begin{array}{cl} X_t &amp;\\text{if } t \\in \\left\\{2k | k \\in \\mathbb{N}\\right\\}\\\\ Y_t &amp;\\text{if } t \\in \\left\\{2k + 1 | k \\in \\mathbb{N}\\right\\}, \\end{array} \\right. \\end{equation*}\\] we have \\(Z_t\\) is weakly stationary but not strongly stationary. \\(\\LARGE{\\bullet}\\) Remark 2.5 (Stationarity of Latent Time Series Processes) (Weakly) Stationary: WN, QN, AR1 (Weakly) Non-Stationary: DR, RW Proof (AR1 is weakly stationary). Consider an AR1 process defined as: \\[\\begin{equation*} X_t = \\phi X_{t-1} + Z_t, \\;\\;\\; Z_t \\overset{iid}{\\sim} \\mathcal{N}(0,\\nu^2), \\end{equation*}\\] where \\(\\mid \\phi \\mid &lt; 1\\) and \\(\\nu^2 &lt; \\infty\\). Then we have \\[\\begin{aligned} {X_t} &amp;= {\\phi }{X_{t - 1}} + {Z_t} = \\phi \\left[ {\\phi {X_{t - 2}} + {Z_{t - 1}}} \\right] + {Z_t} = {\\phi ^2}{X_{t - 2}} + \\phi {Z_{t - 1}} + {Z_t} \\\\ &amp; \\; \\vdots \\\\ &amp;= {\\phi ^k}{X_{t-k}} + \\sum\\limits_{j = 0}^{k - 1} {{\\phi ^j}{Z_{t - j}}} . \\end{aligned} \\] By taking the limit in \\(k\\) (which is perfectly valid as we assume \\(t \\in \\mathbb{Z}\\)), we obtain \\[\\begin{equation*} \\begin{aligned} X_t = \\mathop {\\lim }\\limits_{k \\to \\infty} \\; {X_t} = \\sum\\limits_{j = 0}^{\\infty} {{\\phi ^j}{Z_{t - j}}}. \\end{aligned} \\end{equation*}\\] So we have \\[\\begin{equation*} \\begin{aligned} \\mathbb{E}\\left[X_t\\right] &amp;= \\sum\\limits_{j = 0}^{\\infty} {{\\phi ^j}{\\mathbb{E} [Z_{t - j}]}} = 0, \\\\ \\text{Var}\\left(X_t\\right) &amp;= \\text{Var}\\left(\\sum\\limits_{j = 0}^{\\infty} {{\\phi ^j}{Z_{t - j}}}\\right) = \\sum\\limits_{j = 0}^{\\infty} {\\phi^{2j}} \\text{Var}\\left(Z_{t-j}\\right) = \\nu^2 \\sum\\limits_{j = 0}^{\\infty} {\\phi^{2j}} = \\frac{\\nu^2}{1-\\phi^2} &lt; \\infty. \\end{aligned} \\end{equation*}\\] Moreover, assuming for notational simplicity that \\(h &gt; 1\\), we obtain \\[\\begin{equation*} \\begin{aligned} \\text{Cov}\\left(X_t, X_{t+h}\\right) &amp;= \\phi \\text{Cov}\\left(X_t, X_{t+h-1}\\right) = \\phi^2 \\text{Cov}\\left(X_t, X_{t+h-2}\\right) = \\ldots = \\phi^h \\text{Cov}(X_t, X_t). \\end{aligned} \\end{equation*}\\] In general, when \\(h \\in \\mathbb{Z}\\) we obtain \\[\\begin{equation*} \\begin{aligned} \\text{Cov}\\left(X_t, X_{t+h}\\right) &amp; = \\phi^{|h|} \\text{Cov}(X_t, X_t) = \\phi^{|h|} \\frac{\\nu^2}{1-\\phi^2}, \\end{aligned} \\end{equation*}\\] which is a function of the lag \\(h\\) only. Therefore, this AR1 process is weakly stationary. 2.4 Linear Processes In this section we introduce the concept of linear processes. As a matter of fact, considered stationary models can all, so far, be represented as linear processes. Definition 2.9 (Linear Processes) A stochastic process \\((X_t)\\) is said to be a linear process if it can be expressed as a linear combination of an iid Gaussian sequence (i.e. white noise process), i.e.: \\[{X_t} = \\mu + \\sum\\limits_{j = - \\infty }^\\infty {{\\psi _j}{W_{t - j}}} \\] where \\(W_t \\overset{iid}{\\sim} \\mathcal{N}(0, \\sigma^2)\\) and \\(\\sum\\limits_{j = - \\infty }^\\infty {\\left| {{\\psi _j}} \\right|} &lt; \\infty\\). Notice that the condition \\(\\sum\\limits_{j = - \\infty }^\\infty {\\left| {{\\psi _j}} \\right|} &lt; \\infty\\) is required in the definition of linear processes in order to ensure that the series has a limit and is related to the absolutely summable covariance structure, which is defined below. Definition 2.10 (Absolutely Summable Covariance Structure) A process \\((X_t)\\) is said to have an absolutely summable covariance structure if \\(\\sum\\limits_{h = - \\infty }^\\infty {\\left| \\gamma_X(h) \\right|} &lt; \\infty\\). Remark 2.6 (Properties of Linear Processes) All linear processes are stationary since \\[\\begin{aligned} \\mathbb{E}[X_t] &amp;= \\mu, \\\\ \\gamma(h) &amp;= \\sigma^2\\sum\\limits_{j = - \\infty }^\\infty {{\\psi _j}{\\psi _{j+h}}}. \\end{aligned}\\] All linear processes have absolutely summable covariance structures. Proof (ACV of Linear Processes). \\[\\begin{align*} \\gamma(h) &amp;= \\text{Cov}(X_t, X_{t+h}) = \\text{Cov}(\\mu+\\sum_{j=-\\infty}^{\\infty} \\psi_j W_{t-j}, \\mu+\\sum_{j=-\\infty}^{\\infty} \\psi_j W_{t+h-j})\\\\ &amp;= \\text{Cov}(\\sum_{j=-\\infty}^{\\infty} \\psi_j W_{t-j}, \\sum_{j=-\\infty}^{\\infty} \\psi_j W_{t-(j-h)}) \\\\ &amp;= \\text{Cov}(\\sum_{j=-\\infty}^{\\infty} \\psi_j W_{t-j}, \\sum_{j=-\\infty}^{\\infty} \\psi_{j+h} W_{t-j}) \\\\ &amp;= \\sum_{j=-\\infty}^{\\infty} \\psi_j \\psi_{j+h} \\text{Cov}(W_{t-j}, W_{t-j}) \\\\ &amp;= \\sigma^2\\sum\\limits_{j = - \\infty }^\\infty {{\\psi _j}{\\psi _{j+h}}}. \\end{align*}\\] Proof (All linear processes have absolutely summable covariance structures.). \\[\\begin{align*} \\sum_{h=-\\infty}^{\\infty} \\mid \\gamma(h) \\mid &amp;= \\sum_{h=-\\infty}^{\\infty} \\sigma^2 \\mid \\sum_{j=-\\infty}^{\\infty} \\psi_j \\psi_{j+h} \\mid \\\\ &amp;\\leq \\sigma^2 \\sum_{h=-\\infty}^{\\infty} \\sum_{j=-\\infty}^{\\infty} \\mid \\psi_j \\psi_{j+h} \\mid \\\\ &amp;= \\sigma^2 \\sum_{j=-\\infty}^{\\infty} \\sum_{h=-\\infty}^{\\infty} \\mid \\psi_j \\mid \\cdot \\mid \\psi_{j+h} \\mid \\\\ &amp;= \\sigma^2 \\sum_{j=-\\infty}^{\\infty} \\mid \\psi_j \\mid \\sum_{h=-\\infty}^{\\infty} \\mid \\psi_{j+h} \\mid \\\\ &amp;= \\sigma^2 \\big( \\sum_{j=-\\infty}^{\\infty} \\mid \\psi_j \\mid \\big)^2 &lt; \\infty \\end{align*}\\] So with the assumption that \\(\\sum_{j=-\\infty}^{\\infty} \\mid \\psi_j \\mid &lt; \\infty\\), we obtain that all linear processes have absolutely summable covariance structures. Notice that here we have shown that the condition \\(\\sum\\limits_{j = - \\infty }^\\infty {\\left| {{\\psi _j}} \\right|} &lt; \\infty\\) is actually stronger than \\(\\sum\\limits_{h = - \\infty }^\\infty {\\left| \\gamma(h) \\right|} &lt; \\infty\\). Example 2.8 (AR1 is a linear process) When we prove above that AR1 is weakly stationary, we have shown that for an AR1 process \\(X_t = \\phi X_{t-1} + Z_t, \\;\\;\\; Z_t \\overset{iid}{\\sim} \\mathcal{N}(0,\\nu^2)\\), it can be represented as \\[\\begin{align*} X_t = \\sum\\limits_{j = 0}^{\\infty} {{\\phi ^j}{Z_{t - j}}}. \\end{align*}\\] Therefore, AR1 is a linear process. \\(\\LARGE{\\bullet}\\) 2.5 Basic Time Series Models We first introduce some latent time series models that are commonly used, especially in the calibration procedure of inertial sensors. Definition 2.11 (Gaussian White Noise) The Gaussian White Noise (WN) process with parameter \\(\\sigma^2 \\in \\mathbb{R}^+\\) is defined as \\[\\begin{equation*} X_t \\overset{iid}{\\sim} \\mathcal{N}\\left(0, \\sigma^2 \\right) \\end{equation*}\\] where “iid” stands for “independent and identically distributed”. Definition 2.12 (Quantization Noise) The Quantization Noise (QN) process with parameter \\(Q^2 \\in \\mathbb{R}^+\\) is a process with Power Spectral Density (PSD) of the form \\[\\begin{equation*} S_{X}(f) = 4 Q^2 \\sin^2 \\left( \\frac{\\pi f}{\\Delta t} \\right) \\Delta t, \\;\\; f &lt; \\frac{\\Delta t}{2}. \\end{equation*}\\] Definition 2.13 (Drift) The Drift (DR) process with parameter \\(\\omega \\in \\Omega\\), where \\(\\Omega\\) is either \\(\\mathbb{R}^+\\) or \\(\\mathbb{R}^-\\), is defined as \\[\\begin{equation*} X_t = \\omega t. \\end{equation*}\\] Definition 2.14 (Random Walk) The Random Walk (RW) process with parameter \\(\\gamma^2 \\in \\mathbb{R}^+\\) is defined as \\[\\begin{equation*} X_t = X_{t-1} + \\epsilon_t \\;\\; \\text{where}\\;\\; \\epsilon_t \\overset{iid}{\\sim} \\mathcal{N}\\left(0, \\gamma^2 \\right)\\;\\; \\text{and}\\;\\; X_0 = 0. \\end{equation*}\\] Definition 2.15 (Auto-Regressive) The Auto-Regressive process of Order 1 (AR1) with parameter \\(\\phi \\in (-1, +1)\\) and \\(\\upsilon^2 \\in \\mathbb{R}^+\\) is defined as \\[\\begin{equation*} X_t = \\phi X_{t-1} + Z_t, \\;\\;\\; Z_t \\overset{iid}{\\sim} \\mathcal{N}(0,\\upsilon^2). \\end{equation*}\\] Definition 2.16 (Gauss Markov) The Gauss Markov process of Order 1 (GM) with parameter \\(\\beta \\in \\mathbb{R}\\) and \\(\\sigma_G^2 \\in \\mathbb{R}^+\\) is defined as \\[\\begin{equation*} X_t = \\exp(-\\beta \\Delta_t) X_{t-1} + Z_t, \\;\\;\\; Z_t \\overset{iid}{\\sim} \\mathcal{N}(0,\\sigma^2_{G}(1-\\exp(-2\\beta\\Delta t))) \\end{equation*}\\] where \\(\\Delta t\\) denotes the time between \\(X_t\\) and \\(X_{t-1}\\). Remark 2.7 (GM and AR1) A GM process is a one-to-one reparametrization of an AR1 process. In the following, we will only discuss AR1 processes but all results remain valid for GM processes. With the above defined latent time series processes, we introduce the composite stochastic process, which is widely used in the estimation procedure of inertial sensor stochastic calibration. Definition 2.17 (Composite Stochastic Process) A composite stochastic process is a sum of latent processes. We implicitly assume that these latent processes are independent. Example 2.9 (2*AR1 + WN) The composite stochastic process of “2*AR1 + WN&quot; is given as \\[\\begin{align} Y_t &amp;= \\phi_1 Y_{t-1} + Z_t, \\;\\;\\; Z_t \\overset{iid}{\\sim} \\mathcal{N}(0,\\upsilon_1^2),\\\\ W_t &amp;= \\phi_2 W_{t-1} + U_t, \\;\\;\\; U_t \\overset{iid}{\\sim} \\mathcal{N}(0,\\upsilon_2^2),\\\\ Q_t &amp;\\overset{iid}{\\sim} \\mathcal{N}(0,\\sigma^2),\\\\ X_t &amp;= Y_t + W_t + Q_t, \\end{align}\\] where \\(Y_t\\), \\(W_t\\) and \\(Q_t\\) are independent and only \\(X_t\\) is observed. \\(\\LARGE{\\bullet}\\) 2.6 Fundamental Representations of Time Series We conclude this chapter by summarizing the fundamental representations of time series. If two processes have the same fundamental representations, then these two processes are the same. There are two most commonly used fundamental representations of time series, i.e. ACV and ACF; Power Spectral Density (PSD). Remark 2.8 (ACV and ACF as fundamental representation) If we consider a zero mean normally distributed process, it is clear that its joint distribution is fully characterized by the autocovariances \\(\\mathbb{E}[X_t X_{t+h}]\\) since the joint probability density only depends on these covariances. Once we know the autocovariances we know everything there is to know about the process and therefore: if two processes have the same autocovariance function, then they are the same process. Remark 2.9 (PSD as fundamental representation) The PSD is defined as \\[\\begin{equation*} S_X(f) = \\int_{- \\infty}^{\\infty} \\gamma_{X}(h)\\,e^{-ifh}dh, \\end{equation*}\\] where \\(f\\) is a frequency. Hence, the PSD is a Fourier Transform (FT) of the autocovariance function which describes the variance of a time series over frequencies (with respect to lags \\(h\\)). Given that the definition of the PSD, as for the autocovariance function, once we know the PSD we know everything there is to know about the process and therefore: if two processes have the same PSD, then they are the same process. 2.7 Estimation Problems with Time Series Estimation in the context of time series is not as straightforward as in the iid case. For example, let us consider the easiest case of estimation: the sample mean of a stationary time series. Example 2.10 (Estimation with Sample Mean) Let \\((X_t)\\) be a stationary time series, so we have that \\(\\mathbb{E}[X_t] = \\mu\\) and the value of \\(\\mu\\) can be estimated by the sample mean, i.e. \\[\\begin{equation*} \\bar{X} = \\frac{1}{T} \\sum_{t = 1}^T X_t. \\end{equation*}\\] Using the properties of a stationary process, we obtain \\[\\begin{equation*} \\text{Var} \\left(\\bar{X}\\right) = \\frac{\\gamma(0)}{T} \\sum_{h = -T}^{T} \\left(1 - \\frac{|h|}{T}\\right) \\rho(h) \\end{equation*}\\] since \\[\\begin{align*} \\text{Var}(\\bar{X}) &amp;= \\frac{1}{T^2} \\text{Var}(\\sum_{t=1}^T X_t) = \\frac{1}{T^2} (\\sum_{t=1}^T \\text{Var}(X_t) + 2\\underset{1 \\leq t&lt;s\\leq T}{\\sum\\sum} \\text{Cov}(X_t, X_s)) \\\\ &amp;= \\frac{1}{T^2} (T\\gamma(0) + 2(T-1)\\gamma(1) + 2(T-2)\\gamma(2) + \\ldots + 2\\gamma(T-1)) \\\\ &amp;= \\frac{\\gamma(0)}{T^2} (T+ 2(T-1)\\rho(1) + \\ldots + 2\\rho(T-1)) \\\\ &amp;= \\frac{\\gamma(0)}{T} + \\frac{2\\gamma(0)}{T} \\sum_{h=1}^{T-1} (1-\\frac{h}{T})\\rho(h) \\\\ &amp;= \\frac{\\gamma(0)}{T} \\sum_{h = -(T-1)}^{T-1} \\left(1 - \\frac{|h|}{T}\\right) \\rho(h) \\\\ &amp;= \\frac{\\gamma(0)}{T} \\sum_{h = -T}^{T} \\left(1 - \\frac{|h|}{T}\\right) \\rho(h). \\end{align*}\\] \\(\\LARGE{\\bullet}\\) Example 2.11 (Estimation with Sample Mean in AR1) As in the previous example, let us consider a stationary AR1 process, i.e. \\[\\begin{equation*} X_t = \\phi X_{t-1} + Z_t, \\;\\;\\; \\text{where} \\;\\;\\; |\\phi| &lt; 1 \\;\\;\\; \\text{and} \\;\\;\\; Z_t \\overset{iid}{\\sim} \\mathcal{N} \\left(0, \\nu^2\\right). \\end{equation*}\\] We have obtained before that in AR1, \\(\\gamma(h) = \\phi^h \\sigma^2 \\left(1 - \\phi^2\\right)^{-1}\\). Therefore, we obtain (after some computations): \\[\\begin{equation*} \\text{Var} \\left( {\\bar X} \\right) = \\frac{\\nu^2 \\left( T - 2\\phi - T \\phi^2 + 2 \\phi^{T + 1}\\right)}{T^2\\left(1-\\phi^2\\right)\\left(1-\\phi\\right)^2}. \\end{equation*}\\] Unfortunately, deriving such an exact formula is often difficult when considering more complex models. Therefore, asymptotic approximations are often employed to simplify the calculation. For example, in this AR1 case we have \\[\\begin{equation*} \\lim_{T \\to \\infty } \\; T \\text{Var} \\left( {\\bar X} \\right) = \\frac{\\nu^2}{\\left(1-\\phi\\right)^2}, \\end{equation*}\\] providing the following approximate formula \\[\\begin{equation*} \\text{Var} \\left( {\\bar X} \\right) \\approx \\frac{\\nu^2}{T \\left(1-\\phi\\right)^2}. \\end{equation*}\\] Alternatively, simulation methods can also be employed. For example, one could compute \\(\\text{Var} \\left( {\\bar X} \\right)\\) as follows: Step 1: Simulate under the assumed model, i.e. \\(X_t^* \\sim F_{\\theta_0}\\), where \\(F_{\\theta_0}\\) denotes the true model (in this case an AR1 process). Step 2: Compute \\({\\bar X^*}\\) (i.e. average based on \\((X_t^*)\\)). Step 3: Repeat Steps 1 and 2 \\(B\\) times. Step 4: Compute the empirical variance \\({\\bar X^*}\\) (based on \\(B\\) independent replications). The above procedure is known as Monte-Carlo method (in this case it is actually a Monte-Carlo integral) and is closely related to the concept of parametric bootstrap (see Efron and Tibshirani (1994)) which is a very popular tool in statistics. \\(\\LARGE{\\bullet}\\) Now we define the classical estimators of \\(\\gamma(h)\\) and \\(\\rho(h)\\) for AutoCovariance and AutoCorrelation functions. Definition 2.18 (Sample AutoCovariance Function) The sample autocovariance function is defined as \\[\\begin{equation*} \\hat{\\gamma}(h) = \\frac{1}{T} \\sum_{t = 1}^{T-h} \\left(X_{t} - \\bar{X}\\right) \\left(X_{t+h} - \\bar{X}\\right) \\end{equation*}\\] with \\(\\hat{\\gamma}(h) = \\hat{\\gamma}(-h)\\) for \\(h = 0, 1, ..., k\\), where \\(k\\) is a fixed integer. Definition 2.19 (Sample AutoCorrelation Function) The sample autocorrelation function is defined as \\[\\begin{equation*} \\hat{\\rho}(h) = \\frac{\\hat{\\gamma}(h)}{\\hat{\\gamma}(0)} \\end{equation*}\\] with \\(\\hat{\\rho}(h) = \\hat{\\rho}(-h)\\) for \\(h = 0, 1, ..., k\\), where \\(k\\) is a fixed integer. We will discuss more about the properties of these estimators in the next chapter. References "],
["properties-of-statistical-estimators.html", "Chapter 3 Properties of Statistical Estimators 3.1 Extremum Estimators 3.2 Consistency 3.3 Asymptotic Normality", " Chapter 3 Properties of Statistical Estimators In this chapter, we will provide a review of the properties of statistical estimators. This chapter is organized with the following outline: Extremum estimators; Consistency; Asymptotic normality. 3.1 Extremum Estimators In this section, we will introduce a commonly used class of estimators, extremum estimators, and some examples of it. Definition 3.1 (Extremum Estimators) Many estimators have a common structure, which is often useful to study their asymptotic properties. One structure or framework is the class of estimators that maximize some objective function, referred to as extremum estimators, which can can be defined as follows: \\[\\begin{equation*} \\hat{\\boldsymbol{\\theta}} \\equiv \\underset{\\boldsymbol{\\theta} \\in \\boldsymbol{\\Theta}}{\\text{argmax}} \\; \\hat{Q}_n(\\boldsymbol{\\theta}) \\end{equation*}\\] where \\(\\boldsymbol{\\theta}\\) and \\(\\boldsymbol{\\Theta}\\) denote, respectively, the parameter vector of interest and its set of possible values. The vast majority of statistical estimators can be represented as extremum estimators. For example, least squares, maximum likelihood or (generalized) method of moment estimators can all be represented as extremum estimators. Example 3.1 (Least Squares Estimator as Extremum Estimator) Consider the linear model \\(\\boldsymbol{y} = \\boldsymbol{X} \\boldsymbol{\\beta}_0 + \\boldsymbol{\\epsilon}\\) where \\(\\boldsymbol{X} \\in \\mathbb{R}^{n \\times p}\\) is a full rank constant matrix, \\(\\boldsymbol{\\beta} \\in {\\mathcal{B}} \\subseteq \\mathbb{R}^p\\) and \\(\\epsilon_i \\overset{iid}{\\sim} \\mathcal{N}(0, \\sigma_\\epsilon^2)\\). Let \\(\\hat{\\boldsymbol{\\beta}}\\) denote the Least Squares Estimator (LSE) of \\(\\boldsymbol{\\beta}_0\\), i.e. \\[\\begin{equation*} \\hat{\\boldsymbol{\\beta}} = \\left(\\boldsymbol{X}^T \\boldsymbol{X} \\right)^{-1} \\boldsymbol{X}^T \\boldsymbol{y}. \\end{equation*}\\] This LSE is an extremum estimator since it can be expressed as \\[\\begin{equation*} \\hat{\\boldsymbol{\\beta}} = \\underset{\\boldsymbol{\\beta} \\in \\mathcal{B}}{\\text{argmax}} \\; -||\\boldsymbol{y} - \\boldsymbol{X} \\boldsymbol{\\beta} ||_2^2. \\end{equation*}\\] \\(\\LARGE{\\bullet}\\) Example 3.2 (Maximum Likelihood Estimator as Extremum Estimator) Let \\(Z_1, \\ldots, Z_n\\) be an iid sample with pdf \\(f(z|\\boldsymbol{\\theta}_0)\\). The Maximum Likelihood Estimator (MLE) is given by \\[\\begin{equation*} \\hat{\\boldsymbol{\\theta}} = \\underset{\\boldsymbol{\\theta} \\in \\boldsymbol{\\Theta}}{\\text{argmax}} \\; \\frac{1}{n} \\sum_{i = 1}^{n} \\text{log}\\left[f\\left(z_i| \\boldsymbol{\\theta}\\right)\\right]. \\end{equation*}\\] Here instead of the actual log-likelihood, we are actually using a normalized log-likelihood, which has no impact on the estimator but the normalized form is more convenient to use when we let \\(n \\to \\infty\\). Therefore, the MLE can be seen as an extremum estimator with \\[\\begin{equation*} \\hat{Q}_n(\\boldsymbol{\\theta}) = \\frac{1}{n} \\sum_{i = 1}^{n} \\text{log}\\left[f\\left(z_i| \\boldsymbol{\\theta}\\right)\\right]. \\end{equation*}\\] \\(\\LARGE{\\bullet}\\) Definition 3.2 (Generalized Method of Moments) Let \\(Z_1, \\ldots, Z_n\\) be an iid sample with pdf \\(f(z|\\boldsymbol{\\theta}_0)\\). Suppose that there is a moment function vector \\(\\boldsymbol{g}(z | \\boldsymbol{\\theta})\\) such that \\(\\mathbb{E}[\\boldsymbol{g} (z | \\boldsymbol{\\theta}_0)] = 0\\). Then the Generalized Method of Moments (GMM) estimator of \\(\\boldsymbol{\\theta}_0\\) is defined as \\[\\begin{equation*} \\hat{\\boldsymbol{\\theta}} = \\underset{\\boldsymbol{\\theta} \\in \\boldsymbol{\\Theta}}{\\text{argmax}} \\; - \\left[\\frac{1}{n} \\sum_{i = 1}^n \\boldsymbol{g}(z_i | \\boldsymbol{\\theta}) \\right]^T \\widehat{\\boldsymbol{W}} \\left[\\frac{1}{n} \\sum_{i = 1}^n \\boldsymbol{g}(z_i | \\boldsymbol{\\theta}) \\right], \\end{equation*}\\] where \\(\\widehat{\\boldsymbol{W}}\\) is an positive definite matrix of appropriate dimension. Alternatively (but equivalently), we can define GMM estimator as \\[\\begin{equation*} \\hat{\\boldsymbol{\\theta}} = \\underset{\\boldsymbol{\\theta} \\in \\boldsymbol{\\Theta}}{\\text{argmax}} \\; - || \\hat{\\boldsymbol{\\mu}} - \\boldsymbol{\\mu}(\\boldsymbol{\\theta}) ||_{\\widehat{\\boldsymbol{W}}}^2, \\end{equation*}\\] where \\(|| \\boldsymbol{x} ||_{\\boldsymbol{A}}^2 = \\boldsymbol{x}^T \\boldsymbol{A} \\boldsymbol{x}\\), and where \\(\\hat{\\boldsymbol{\\mu}}\\) and \\(\\boldsymbol{\\mu}(\\boldsymbol{\\theta})\\) denote, respectively, the empirical and model based moments. We will use this form of definition of GMM estimator more often. Example 3.3 (A Simple GMM Estimator as Extremum Estimator) Let \\(Z_i \\overset{iid}{\\sim} \\mathcal{N}(\\mu_0, \\sigma^2_0)\\) and \\(\\boldsymbol{\\theta}_0 = (\\mu_0, \\sigma_0^2)^T\\). Suppose we wish to estimate \\(\\boldsymbol{\\theta}_0\\) by matching the first three empirical moments with their theoretical counterparts. In this case, a reasonable moment function or condition defining a GMM estimator is given by: \\[\\begin{equation*} \\boldsymbol{g} (Z | \\boldsymbol{\\theta}) = \\begin{bmatrix} Z - \\mu\\\\ Z^2 - \\left(\\mu^2 + \\sigma^2\\right)\\\\ Z^3 - \\left(\\mu^3 + 3 \\mu \\sigma^2\\right) \\end{bmatrix}. \\end{equation*}\\] Notice that \\(\\frac{1}{n} \\sum_{i=1}^n \\boldsymbol{g} (Z_i | \\boldsymbol{\\theta}) = \\hat{\\boldsymbol{\\gamma}} - \\boldsymbol{\\gamma}(\\boldsymbol{\\theta})\\), where \\(\\hat{\\boldsymbol{\\gamma}}\\) and \\(\\boldsymbol{\\gamma}(\\boldsymbol{\\theta})\\) denote, respectively, the empirical and model based moments, i.e. \\[\\begin{equation*} \\hat{\\boldsymbol{\\gamma}} = \\frac{1}{n} \\sum_{i = 1}^n \\begin{bmatrix} Z_i\\\\ Z_i^2\\\\ Z_i^3\\\\ \\end{bmatrix}, \\;\\;\\;\\; \\boldsymbol{\\gamma}(\\boldsymbol{\\theta}) = \\begin{bmatrix} \\mu\\\\ \\mu^2 + \\sigma^2\\\\ \\mu^3 + 3 \\mu \\sigma^2 \\end{bmatrix}. \\end{equation*}\\] Therefore we can write the GMM estimator of \\(\\boldsymbol{\\theta}_0\\) as \\[\\begin{equation*} \\hat{\\boldsymbol{\\theta}} = \\underset{\\boldsymbol{\\theta} \\in \\boldsymbol{\\Theta}}{\\text{argmin}} \\; || \\hat{\\boldsymbol{\\gamma}} - \\boldsymbol{\\gamma} (\\boldsymbol{\\theta}) ||_{\\widehat{\\boldsymbol{W}}}^2 = \\underset{\\boldsymbol{\\theta} \\in \\boldsymbol{\\Theta}}{\\text{argmax}} \\; - || \\hat{\\boldsymbol{\\gamma}} - \\boldsymbol{\\gamma} (\\boldsymbol{\\theta}) ||_{\\widehat{\\boldsymbol{W}}}^2 \\end{equation*}\\] \\(\\LARGE{\\bullet}\\) 3.2 Consistency In this section, we will introduce one of the most important properties of statistical estimators, consistency. And we will discuss in details about the conditions for consistency of the extremum estimators. Definition 3.3 (Consistency) An estimator \\(\\hat{\\boldsymbol{\\theta}}\\) is said to be consistent or weakly consistent if it converges in probability to \\(\\boldsymbol{\\theta}_0\\), i.e. \\[\\begin{equation*} \\underset{n \\to \\infty}{\\text{lim}} \\mathbb{P} (||\\hat{\\boldsymbol{\\theta}} - \\boldsymbol{\\theta}_0||_2 \\geq \\epsilon) = 0, \\end{equation*}\\] for all \\(\\epsilon &gt;0\\). In Layman’s term, consistency simply means that if \\(n\\) is large enough, then \\(\\hat{\\boldsymbol{\\theta}}\\) will be arbitrarily close to \\(\\boldsymbol{\\theta}_0\\) (i.e. inside of an hypersphere of radius \\(\\epsilon\\) centered at \\(\\boldsymbol{\\theta}_0\\)). This also means the procedure (i.e. our estimator \\(\\hat{\\boldsymbol{\\theta}}\\)) based on unlimited data will be able to identify the underlying truth (i.e. \\(\\boldsymbol{\\theta}_0\\)). Figure 3.1: Interpretation of consistency To show the consistency of estimators, we often make use of the following two important results: Theorem 3.1 (Weak Law of Large Number) Suppose \\(X_i\\) are iid random variables with finite mean \\(\\mu\\) (i.e. \\(\\mathbb{E}[X_i] = \\mu\\)) and finite variance. Let \\(\\bar{X}_n = \\frac{1}{n} \\sum_{i = 1}^n X_i\\), then \\(\\bar{X}_n \\overset{\\mathcal{P}}{\\mapsto} \\mu\\). Theorem 3.2 (Continuous Mapping Theorem) If \\(Y_n \\overset{\\mathcal{P}}{\\mapsto} \\mu\\) and \\(g(\\cdot)\\) is a continuous function, then \\(g(Y_n) \\overset{\\mathcal{P}}{\\mapsto} g(\\mu)\\). Here we present a simple example to prove the consistency of an estimator with the above two results. Example 3.4 (Consistency in Exponential Distribution) Suppose we have an iid sample from exponential distribution, i.e. \\(X_i \\overset{iid}{\\sim} \\text{exp}(\\lambda_0),\\; \\lambda_0 \\in \\mathbb{R}^+, \\; i = 1,..., n\\). So assuming \\(X \\geq 0\\), the density of \\(X\\) is given by \\[\\begin{equation*} f(x|\\lambda) = \\lambda \\text{exp}\\left( - \\lambda x \\right). \\end{equation*}\\] In this example, we want to show that the MLE for \\(\\lambda_0\\) is a consistent estimator of \\(\\lambda_0\\). First, we want to find the MLE for \\(\\lambda_0\\). The normalized log-likelihood function is given by \\[\\begin{equation*} \\mathcal{L}(\\lambda | X_1, ..., X_n) = \\text{log}(\\lambda) - \\lambda \\bar{X}_n. \\end{equation*}\\] By solving \\[\\begin{equation*} \\frac{\\partial}{\\partial \\lambda} \\; \\mathcal{L}(\\lambda | X_1, \\ldots, X_n) = \\frac{1}{\\lambda} - \\bar{X}_n = 0, \\end{equation*}\\] we obtain \\(\\hat{\\lambda} = \\frac{1}{\\bar{X}_n}\\). We verify that \\[\\begin{equation*} \\frac{\\partial^2}{\\partial \\lambda^2} \\; \\mathcal{L}(\\lambda | X_1, \\ldots, X_n) = -\\frac{1}{\\lambda^2} &lt; 0, \\end{equation*}\\] which implies that \\(\\hat{\\lambda}\\) is the maxima of \\(\\mathcal{L}(\\lambda | X_1, \\ldots, X_n)\\). Therefore, the MLE for \\(\\lambda_0\\) is \\(\\hat{\\lambda} = \\frac{1}{\\bar{X}_n}\\). By Weak Law of Large Number, we have \\(\\bar{X}_n \\overset{\\mathcal{P}}{\\mapsto} \\mu\\), where is given by \\[\\begin{equation*} \\mu = \\mathbb{E}[X_i] = \\int_{0}^{\\infty} x \\lambda_0 \\text{exp}\\left( - \\lambda_0 x \\right) dx = \\frac{1}{\\lambda_0}. \\end{equation*}\\] And also since the function \\(g(x) = 1/x\\) is continuous in \\(\\mathbb{R}^+\\), we obtain by the Continuous Mapping Theorem that \\(\\hat{\\lambda} \\overset{\\mathcal{P}}{\\mapsto} \\lambda_0\\), which concludes that the MLE for \\(\\lambda_0\\) is a consistent estimator of \\(\\lambda_0\\) in exponential distribution. \\(\\LARGE{\\bullet}\\) 3.2.1 Consistency of Extremum Estimators When considering real-life problems, the above approach based on Weak Law of Large Number and Continuous Mapping Theorem is in general not flexible enough. Therefore, we often rely on the results as following. Theorem 3.3 (Consistency of Extremum Estimators) If there is a function \\({Q}_0 (\\boldsymbol{\\theta})\\) such that: C1. \\({Q}_0 (\\boldsymbol{\\theta})\\) is uniquely maximized in \\(\\boldsymbol{\\theta}_0\\), C2. \\(\\boldsymbol{\\Theta}\\) is compact, C3. \\({Q}_0 (\\boldsymbol{\\theta})\\) is continuous in \\(\\boldsymbol{\\theta}\\), C4. \\(\\hat{Q}_n (\\boldsymbol{\\theta})\\) converges uniformly in probability to \\(Q_0 (\\boldsymbol{\\theta})\\), then we have \\(\\hat{\\boldsymbol{\\theta}} \\overset{\\mathcal{P}}{\\mapsto} \\boldsymbol{\\theta}_0\\). Definition 3.4 (Compactness) We say \\(\\boldsymbol{\\Theta}\\) is compact if every open cover of \\(\\boldsymbol{\\Theta}\\) contains a finite subcover. If \\(\\boldsymbol{\\Theta}\\) is compact, then \\(\\boldsymbol{\\Theta}\\) is closed (i.e. containing all its limit points) and bounded (i.e. all its points are within some finite distance of each other). Definition 3.5 (Uniform Convergence in Probability) \\(\\hat{Q}_n (\\boldsymbol{\\theta})\\) is said to converges uniformly in probability to \\(Q_0 (\\boldsymbol{\\theta})\\) if \\(\\underset{\\boldsymbol{\\theta} \\in \\boldsymbol{\\Theta}}{\\text{sup}} \\; |\\hat{Q}_n (\\boldsymbol{\\theta}) - {Q}_0 (\\boldsymbol{\\theta})| \\overset{\\mathcal{P}}{\\mapsto} 0\\). Theorem 3.3 is an important result as it provides a general approach to prove the consistency of the class of extremum estimators. Notice that in this theorem: Condition (C1) is substantive and there are well-known examples where it fails. We will discuss further on how this assumption can (in some cases) be verified in practice. Condition (C2) is also substantive as it requires that there exist some known bounds on the parameters. In practice, this assumption is often neglected although it is in most cases unrealistic to assume it. Condition (C3) and (C4) are often referred to as “standard regularity conditions”. They are typically satisfied. The verification of these conditions will be discussed further later in this section. Proof (Consistency of Extremum Estimators). Let \\(\\mathcal{G}\\) be an \\(\\epsilon\\)-neighborhood centered at \\(\\boldsymbol{\\theta}_0\\) for some \\(\\epsilon &gt; 0\\), i.e. \\(\\mathcal{G} = \\{ \\boldsymbol{\\theta} \\in \\boldsymbol{\\Theta}: || \\boldsymbol{\\theta} - \\boldsymbol{\\theta}_0 ||_2 &lt; \\epsilon\\}\\) for some \\(\\epsilon &gt; 0\\). We want to show \\(\\hat{\\boldsymbol{\\theta}} \\overset{\\mathcal{P}}{\\mapsto} \\boldsymbol{\\theta}_0\\), which is equivalent to show \\[\\begin{equation*} \\underset{n \\to \\infty}{\\text{lim}} \\mathbb{P}(||\\boldsymbol{\\theta} - \\boldsymbol{\\theta}_0 ||_2 \\geq \\epsilon) = \\underset{n \\to \\infty}{\\text{lim}} \\mathbb{P}(\\hat{\\boldsymbol{\\theta}} \\notin \\mathcal{G}) = 0 \\end{equation*}\\] Define \\(\\gamma = Q_0(\\boldsymbol{\\theta}_0) - \\underset{\\boldsymbol{\\theta} \\in \\boldsymbol{\\Theta} \\setminus \\mathcal{G}}{\\text{sup}} Q_0({\\boldsymbol{\\theta}}) &gt; 0 \\;\\;\\) by condition C1. So \\(\\hat{\\boldsymbol{\\theta}} \\notin \\mathcal{G}\\) implies that \\(Q_0(\\hat{\\boldsymbol{\\theta}}) \\leq \\underset{\\boldsymbol{\\theta} \\in \\boldsymbol{\\Theta} \\setminus \\mathcal{G}}{\\text{sup}} Q_0({\\boldsymbol{\\theta}}) = Q_0(\\boldsymbol{\\theta}_0) - \\gamma\\). Let \\(\\mathcal{A} = \\{ Q_0(\\hat{\\boldsymbol{\\theta}}) \\leq Q_0(\\boldsymbol{\\theta}_0) - \\gamma \\}\\). So \\(\\underset{n \\to \\infty}{\\text{lim}}\\mathbb{P}(\\hat{\\boldsymbol{\\theta}} \\notin \\mathcal{G}) \\leq \\underset{n \\to \\infty}{\\text{lim}}\\mathbb{P}(\\mathcal{A})\\). Now we define the following events: \\[\\begin{align*} \\mathcal{B} &amp;= \\{|\\hat{Q_n}(\\hat{\\boldsymbol{\\theta}}) - Q_0(\\hat{\\boldsymbol{\\theta}})| &gt; \\gamma/3 \\}, \\\\ \\mathcal{C} &amp;= \\{|\\hat{Q_n}(\\boldsymbol{\\theta}_0) - Q_0(\\boldsymbol{\\theta}_0)| &gt; \\gamma/3 \\}, \\\\ \\mathcal{D} &amp;= \\{\\underset{\\boldsymbol{\\theta} \\in \\boldsymbol{\\Theta}}{\\text{sup}} |\\hat{Q_n}(\\boldsymbol{\\theta}) - Q_0(\\boldsymbol{\\theta})| &gt;\\gamma/3 \\}. \\end{align*}\\] So we have \\[\\begin{align*} \\mathbb{P} (\\mathcal{A}) &amp;\\leq \\mathbb{P} (\\mathcal{A} \\cup (\\mathcal{B} \\cup \\mathcal{C})) + \\mathbb{P}(\\mathcal{B} \\cup \\mathcal{C}) \\\\ &amp;= \\mathbb{P}(\\mathcal{A} \\cap \\mathcal{B}^c \\cap \\mathcal{C}^c) + \\mathbb{P}(\\mathcal{B} \\cup \\mathcal{C}) \\\\ &amp;= \\mathbb{P}(\\emptyset) + \\mathbb{P}(\\mathcal{B} \\cup \\mathcal{C}) \\\\ &amp;= \\mathbb{P}(\\mathcal{B} \\cup \\mathcal{C}). \\end{align*}\\] Notice that \\(\\mathcal{A} \\cap \\mathcal{B}^c \\cap \\mathcal{C}^c = \\emptyset\\) because if \\(\\mathcal{A}\\), \\(\\mathcal{B}^c\\), and \\(\\mathcal{C}^c\\) hold simultaneously, then \\[\\begin{align*} \\hat{Q_n}(\\hat{\\boldsymbol{\\theta}}) &amp;= \\hat{Q_n}(\\hat{\\boldsymbol{\\theta}}) - Q_0(\\hat{\\boldsymbol{\\theta}}) + Q_0(\\hat{\\boldsymbol{\\theta}}) \\\\ &amp;\\leq |\\hat{Q_n}(\\hat{\\boldsymbol{\\theta}}) - Q_0(\\hat{\\boldsymbol{\\theta}})| + Q_0(\\hat{\\boldsymbol{\\theta}}) \\\\ &amp;\\leq \\gamma/3 + Q_0(\\hat{\\boldsymbol{\\theta}}) \\;\\;\\;\\;\\;\\; \\text{since} \\;\\; \\mathcal{B}^c \\;\\; \\text{holds}\\\\ &amp;\\leq Q_0({\\boldsymbol{\\theta}}_0) - 2\\gamma/3 \\;\\;\\;\\;\\;\\; \\text{since} \\;\\; \\mathcal{A} \\;\\; \\text{holds}\\\\ &amp;\\leq Q_0({\\boldsymbol{\\theta}}_0) - \\hat{Q_n}(\\hat{\\boldsymbol{\\theta}}_0) + \\hat{Q_n}(\\hat{\\boldsymbol{\\theta}}_0) - 2\\gamma/3 \\\\ &amp;\\leq |Q_0({\\boldsymbol{\\theta}}_0) - \\hat{Q_n}({\\boldsymbol{\\theta}}_0)| + \\hat{Q_n}({\\boldsymbol{\\theta}}_0) - 2\\gamma/3 \\\\ &amp;\\leq \\hat{Q_n}({\\boldsymbol{\\theta}}_0) - \\gamma/3 \\;\\;\\;\\;\\;\\; \\text{since} \\;\\; \\mathcal{C}^c \\;\\; \\text{holds}\\\\ &amp;&lt; \\hat{Q_n}({\\boldsymbol{\\theta}}_0) \\end{align*}\\] which contradicts that \\(\\hat{\\boldsymbol{\\theta}} = \\underset{\\boldsymbol{\\theta} \\in \\boldsymbol{\\Theta}}{\\text{argmax}} \\hat{Q_n}({\\boldsymbol{\\theta}})\\). So \\[\\begin{align*} \\mathbb{P}(\\mathcal{A}) &amp;= \\mathbb{P}(\\mathcal{B} \\cup \\mathcal{C}) \\\\ &amp;= \\mathbb{P}(|\\hat{Q_n}(\\hat{\\boldsymbol{\\theta}}) - Q_0(\\hat{\\boldsymbol{\\theta}})| &gt; \\gamma/3 \\;\\; \\text{or} \\;\\; |\\hat{Q_n}(\\boldsymbol{\\theta}_0) - Q_0(\\boldsymbol{\\theta}_0)| &gt; \\gamma/3) \\\\ &amp;= \\mathbb{P} (\\underset{\\boldsymbol{\\theta} \\in \\{\\hat{\\boldsymbol{\\theta}}, \\boldsymbol{\\theta}_0\\} }{\\text{sup}} |\\hat{Q_n}(\\boldsymbol{\\theta}) - Q_0(\\boldsymbol{\\theta})| &gt; \\gamma/3) \\\\ &amp; \\leq \\mathbb{P} (\\underset{\\boldsymbol{\\theta} \\in \\boldsymbol{\\Theta} }{\\text{sup}} |\\hat{Q_n}(\\boldsymbol{\\theta}) - Q_0(\\boldsymbol{\\theta})| &gt; \\gamma/3) \\\\ &amp;= \\mathbb{P}(\\mathcal{D}). \\end{align*}\\] So by condition C4, we have \\[\\begin{equation*} \\underset{n \\to \\infty}{\\text{lim}}\\mathbb{P}(\\hat{\\boldsymbol{\\theta}} \\notin \\mathcal{G}) \\leq \\underset{n \\to \\infty}{\\text{lim}} \\mathbb{P}(\\mathcal{A}) \\leq \\underset{n \\to \\infty}{\\text{lim}}\\mathbb{P}(\\mathcal{D}) = 0. \\end{equation*}\\] Therefore, \\(\\underset{n \\to \\infty}{\\text{lim}}\\mathbb{P}(\\hat{\\boldsymbol{\\theta}} \\notin \\mathcal{G}) = 0\\). 3.2.2 Verification of Condition C1 In general, the verification of Condition C1 is difficult and is often assumed in the statistical literature. Here we present two results based on W. K. Newey and McFadden (1994) and Komunjer (2012) respectively, which allow us to verify the condition C1 for GMM-type estimators. A discussion on the verification of this condition for other estimators can for example be found in Chapter 7 of Baltagi (2008). Lemma 3.1 (GMM Identification) If \\(\\boldsymbol{W} &gt; 0\\) (i.e. positive definite), where \\(\\boldsymbol{W}\\) is such that \\(\\widehat{\\boldsymbol{W}} \\overset{\\mathcal{P}}{\\mapsto} \\boldsymbol{W}\\), and for \\(\\boldsymbol{g}_0(\\boldsymbol{\\theta}) = \\mathbb{E}[\\boldsymbol{g}(z|\\boldsymbol{\\theta})]\\), we have \\(\\boldsymbol{g}_0(\\boldsymbol{\\theta}_0)=0\\) and \\(\\boldsymbol{g}_0(\\boldsymbol{\\theta}) \\neq 0\\) if \\(\\boldsymbol{\\theta} \\neq \\boldsymbol{\\theta}_0\\), then \\(Q_0(\\boldsymbol{\\theta}) = -\\boldsymbol{g}_0(\\boldsymbol{\\theta})^T \\boldsymbol{W} \\boldsymbol{g}_0(\\boldsymbol{\\theta})\\) has a unique maximum at \\(\\boldsymbol{\\theta}_0\\). Proof (GMM Identification). Since \\(\\boldsymbol{W} &gt;0\\) and there exists a unique \\(\\boldsymbol{\\theta}_0 \\in \\boldsymbol{\\Theta}\\) such that \\(\\boldsymbol{g}_0(\\boldsymbol{\\theta}) = 0\\), we can say that for all \\(\\boldsymbol{\\theta} \\in \\boldsymbol{\\Theta}\\), \\[\\begin{equation*} Q_0(\\boldsymbol{\\theta}) = -\\boldsymbol{g}_0(\\boldsymbol{\\theta})^T \\boldsymbol{W} \\boldsymbol{g}_0(\\boldsymbol{\\theta}) \\leq -\\boldsymbol{g}_0(\\boldsymbol{\\theta}_0) \\boldsymbol{W} \\boldsymbol{g}_0(\\boldsymbol{\\theta}_0) = Q_0(\\boldsymbol{\\theta_0}). \\end{equation*}\\] Notice that if we write a GMM estimator as in Example 3.3, then the condition \\(\\boldsymbol{g}_0(\\boldsymbol{\\theta}) = 0\\) if and only if \\(\\boldsymbol{\\theta} = \\boldsymbol{\\theta}_0\\) can be replaced by \\(\\boldsymbol{\\gamma}(\\boldsymbol{\\theta}) = \\boldsymbol{\\gamma}(\\boldsymbol{\\theta}_0)\\) if and only if \\(\\boldsymbol{\\theta} = \\boldsymbol{\\theta}_0\\). In order to verify the condition in Lemma 3.1 that \\(\\boldsymbol{g}_0(\\boldsymbol{\\theta}) = 0\\) if and only if \\(\\boldsymbol{\\theta} = \\boldsymbol{\\theta}_0\\) (or alternatively \\(\\boldsymbol{\\gamma}(\\boldsymbol{\\theta}) = \\boldsymbol{\\gamma}(\\boldsymbol{\\theta}_0)\\) if and only if \\(\\boldsymbol{\\theta} = \\boldsymbol{\\theta}_0\\)), the following theorem based on Komunjer (2012) provides us a way. Theorem 3.4 (Homomorphism) Let \\(\\boldsymbol{\\theta} \\in \\boldsymbol{\\Theta} \\subset \\mathbb{R}^p\\). Let \\(\\boldsymbol{g}^*(\\boldsymbol{\\theta})\\) denote a subset of \\(p\\) elements of \\(\\boldsymbol{g}_0 (\\boldsymbol{\\theta}) \\in \\mathbb{R}^q, \\; q \\geq p\\) such that: \\(\\boldsymbol{g}^*(\\boldsymbol{\\theta})\\) is in \\(\\mathcal{C}^2\\) (i.e. \\(\\boldsymbol{g}^*(\\boldsymbol{\\theta})\\) can be differentiated twice); For every \\(\\boldsymbol{\\theta} \\in \\boldsymbol{\\Theta}\\), \\(J(\\boldsymbol{\\theta})\\) is non-negative (or alternatively non-positive), where \\(J(\\boldsymbol{\\theta}) \\equiv \\text{det} (\\frac{\\partial}{\\partial \\boldsymbol{\\theta}^T}\\, \\boldsymbol{g}^*(\\boldsymbol{\\theta}) )\\); \\(||\\boldsymbol{g}^*(\\boldsymbol{\\theta})|| \\to \\infty\\) whenever \\(|| \\boldsymbol{\\theta} || \\to \\infty\\); For every \\(s \\in \\mathbb{R}^p\\) the equation \\(\\boldsymbol{g}^*(\\boldsymbol{\\theta}) = s\\) has countably many (possibly zero) solutions in \\(\\boldsymbol{\\Theta}\\); then \\(\\boldsymbol{g}^*(\\boldsymbol{\\theta})\\) is a homeomorphism (i.e. \\(\\boldsymbol{g}^*(\\boldsymbol{\\theta})\\) is continuous and one-to-one). A direct consequence of Lemma 3.1 and Theorem 3.4 is that any GMM estimator with \\(\\boldsymbol{W} &gt; 0\\) satisfying the conditions of Theorem 3.4 verifies Condition C1 of Theorem 3.3. If one can show that \\(\\boldsymbol{g}^c(\\boldsymbol{\\theta})\\) is in \\(\\mathcal{C}\\) (where \\(\\boldsymbol{g}^c(\\boldsymbol{\\theta})\\) denotes the element of \\(\\boldsymbol{g}_0(\\boldsymbol{\\theta})\\) that are not in \\(\\boldsymbol{g}^*(\\boldsymbol{\\theta})\\)) then Condition C3 of Theorem 3.3 is also verified. When considering a GMM estimator of the form used in Example 3.3, one can simply verify the conditions of Theorem 3.3 with \\(\\boldsymbol{g}(\\boldsymbol{\\theta}) = \\boldsymbol{\\gamma} (\\boldsymbol{\\theta})\\). For Theorem 3.4, in Komunjer (2012) it is actually assumed that \\(\\boldsymbol{\\theta} \\in \\mathbb{R}^p\\) while we assume that \\(\\boldsymbol{\\theta} \\in \\boldsymbol{\\Theta}\\). We use this simplification to avoid an overly technical treatment of this topic. In fact, we assume here that there exists a one-to-one function \\(h(\\cdot)\\) such that \\(h \\, : \\,\\mathbb{R}^p \\mapsto \\boldsymbol{\\Theta}\\). This condition is typically verified in practice. Example 3.5 (An Example to Verify Condition C1) In this example we revisit Example 3.3. Let us say that \\(\\widehat{\\boldsymbol{W}}\\) is such that \\(\\widehat{\\boldsymbol{W}} \\overset{\\mathcal{P}}{\\mapsto} \\boldsymbol{W} &gt; 0\\). We have shown that \\[\\begin{equation*} \\boldsymbol{\\gamma}(\\boldsymbol{\\theta}) = \\begin{bmatrix} \\mu\\\\ \\mu^2 + \\sigma^2\\\\ \\mu^3 + 3 \\mu \\sigma^2 \\end{bmatrix}. \\end{equation*}\\] So we define that \\[\\begin{equation*} \\boldsymbol{g}^*(\\boldsymbol{\\theta}) = \\begin{bmatrix} \\mu\\\\ \\mu^2 + \\sigma^2\\\\ \\end{bmatrix} \\;\\;\\;\\;\\; \\text{and} \\;\\;\\;\\;\\; g^c(\\boldsymbol{\\theta}) = \\begin{bmatrix} \\mu^3 + 3 \\mu \\sigma^2\\\\ \\end{bmatrix}. \\end{equation*}\\] Since the elements of \\(\\boldsymbol{g}^*(\\boldsymbol{\\theta})\\) are polynomial in \\(\\boldsymbol{\\Theta}\\), the condition \\(\\boldsymbol{g}^*(\\boldsymbol{\\theta}) \\in \\mathcal{C}^2\\) is trivially satisfied. Next, since \\[\\begin{equation*} \\frac{\\partial}{\\partial \\boldsymbol{\\theta}^T}\\, \\boldsymbol{g}^*(\\boldsymbol{\\theta}) = \\begin{bmatrix} 1 &amp; 0\\\\ 2\\mu &amp; 1 \\end{bmatrix}, \\end{equation*}\\] we have \\(J(\\boldsymbol{\\theta}) \\equiv \\text{det} (\\frac{\\partial}{\\partial \\boldsymbol{\\theta}^T}\\, \\boldsymbol{g}^*(\\boldsymbol{\\theta}) ) = 1\\). Finally, the last two conditions of Theorem 3.4 are trivially satisfied since \\(||\\boldsymbol{g}^*(\\boldsymbol{\\theta})||\\) can only diverge if \\(|| \\boldsymbol{\\theta} ||\\) diverges and since \\(\\boldsymbol{g}^*(\\boldsymbol{\\theta}) = s\\) has (one) countably solutions in \\(\\boldsymbol{\\Theta}\\). Therefore, it follows from Lemma 3.1 and Theorem 3.4 that the function \\(Q_0(\\boldsymbol{\\theta}) = - || \\boldsymbol{\\gamma}(\\boldsymbol{\\theta}_0) - \\boldsymbol{\\gamma}(\\boldsymbol{\\theta}) ||^2_{\\boldsymbol{W}}\\) is uniquely maximized in \\(\\boldsymbol{\\theta}_0\\). \\(\\LARGE{\\bullet}\\) 3.2.3 Verification of Condition C4 In general, the verification of Condition C4 requires pointwise convergence and Lipschitz continuity as specified in the following theorem, which is a slightly adapted version of the Arzela-Ascoli Theorem. Theorem 3.5 (modified Arzela-Ascoli Theorem) Suppose \\(\\boldsymbol{\\Theta}\\) is compact. If for every \\(\\boldsymbol{\\theta} \\in \\boldsymbol{\\Theta}\\), we have \\(\\hat{Q}_n (\\boldsymbol{\\theta}) \\overset{\\mathcal{P}}{\\mapsto} Q_0 (\\boldsymbol{\\theta})\\), \\(\\hat{Q}_n (\\boldsymbol{\\theta})\\) is almost surely Lipschitz continuous, i.e. \\(\\underset{\\boldsymbol{\\theta}_1, \\boldsymbol{\\theta}_2 \\in \\boldsymbol{\\Theta}}{\\text{sup}} |\\hat{Q}_n (\\boldsymbol{\\theta}_1) - \\hat{Q}_n (\\boldsymbol{\\theta}_2)| \\leq H ||\\boldsymbol{\\theta}_1 - \\boldsymbol{\\theta}_2||\\) where \\(H\\) is bounded almost surely, then \\(\\hat{Q}_n (\\boldsymbol{\\theta})\\) converges uniformly in probability to \\(Q_0 (\\boldsymbol{\\theta})\\). Here we will not discuss how to prove that \\(\\hat{Q}_n (\\boldsymbol{\\theta})\\) is almost surely Lipschitz continuous and assume it for simplicity (more discussion on this topic can for example be found in W. K. Newey and McFadden (1994)). Nevertheless, it worth mentioning that this condition is almost always satisfied in practice and is therefore reasonable to assume for simplicity. Example 3.6 (An Example to Verify Condition C4) In this example we revisit Example 3.3. Since we have \\(Z_i \\overset{iid}{\\sim} \\mathcal{N}(\\mu_0, \\sigma^2_0)\\), we let \\[\\begin{equation*} \\boldsymbol{X}_i \\equiv \\begin{bmatrix} Z_i\\\\ Z_i^2\\\\ Z_i^3 \\end{bmatrix}. \\end{equation*}\\] So by the Weak Law of Large Number (Theorem 3.1), we have \\[\\begin{equation*} \\hat{\\boldsymbol{\\gamma}} = \\frac{1}{n} \\sum_{i = 1}^n \\boldsymbol{X}_i \\overset{\\mathcal{P}}{\\mapsto} \\mathbb{E}[\\boldsymbol{X}_i] = \\boldsymbol{\\gamma}({\\boldsymbol{\\theta}_0}) \\equiv \\boldsymbol{\\gamma}_0. \\end{equation*}\\] Define \\[\\begin{equation*} \\hat{Q}_n (\\boldsymbol{\\theta}) = -||\\hat{\\boldsymbol{\\gamma}}- \\boldsymbol{\\gamma} (\\boldsymbol{\\theta}) ||_{\\widehat{\\boldsymbol{W}}}^2 \\end{equation*}\\] where \\(\\widehat{\\boldsymbol{W}} \\overset{\\mathcal{P}}{\\mapsto} \\boldsymbol{W}\\), and also define \\[\\begin{equation*} Q_0(\\boldsymbol{\\theta}) = -||\\boldsymbol{\\gamma}(\\boldsymbol{\\theta}_0) - \\boldsymbol{\\gamma}(\\boldsymbol{\\theta})||_\\boldsymbol{W}^2. \\end{equation*}\\] In order to show that \\(\\hat{Q}_n (\\boldsymbol{\\theta}) \\overset{\\mathcal{P}}{\\mapsto} Q_0(\\boldsymbol{\\theta})\\) for all \\(\\boldsymbol{\\theta} \\in \\boldsymbol{\\Theta}\\), we want to show that \\(|\\hat{Q}_n (\\boldsymbol{\\theta}) - Q_0(\\boldsymbol{\\theta})| \\overset{\\mathcal{P}}{\\mapsto} 0\\). \\[\\begin{equation*} \\begin{aligned} \\hat{Q}_n (\\boldsymbol{\\theta}) - {Q}_0 (\\boldsymbol{\\theta}) &amp;\\leq |\\hat{Q}_n (\\boldsymbol{\\theta}) - {Q}_0 (\\boldsymbol{\\theta})| = \\left|\\underbrace{ ||\\hat{\\boldsymbol{\\gamma}} - \\boldsymbol{\\gamma} (\\boldsymbol{\\theta}) ||_{\\widehat{\\boldsymbol{W}}}^2 - ||\\gamma_0 - \\boldsymbol{\\gamma} (\\boldsymbol{\\theta}) ||_\\boldsymbol{W}^2}_\\boldsymbol{A}\\right|. \\end{aligned} \\end{equation*}\\] Without loss of generality, we assume that \\(\\boldsymbol{W}^* = \\widehat{\\boldsymbol{W}} - \\boldsymbol{W}\\) and that \\(\\boldsymbol{W}\\) is symmetric. \\[\\begin{align*} \\boldsymbol{A} &amp;= \\hat{\\boldsymbol{\\gamma}}^T \\widehat{\\boldsymbol{W}}\\hat{\\boldsymbol{\\gamma}} + \\boldsymbol{\\gamma}(\\boldsymbol{\\theta})^T \\widehat{\\boldsymbol{W}} \\boldsymbol{\\gamma}(\\boldsymbol{\\theta}) - 2\\hat{\\boldsymbol{\\gamma}}^T\\widehat{\\boldsymbol{W}}\\boldsymbol{\\gamma}(\\boldsymbol{\\theta}) - \\boldsymbol{\\gamma}_0^T \\boldsymbol{W} \\boldsymbol{\\gamma}_0 - \\boldsymbol{\\gamma}(\\boldsymbol{\\theta})^T \\boldsymbol{W} \\boldsymbol{\\gamma}(\\boldsymbol{\\theta}) + 2\\boldsymbol{\\gamma}_0^T \\boldsymbol{W} \\boldsymbol{\\gamma}(\\boldsymbol{\\theta}) \\\\ &amp;= ||\\hat{\\boldsymbol{\\gamma}} - \\boldsymbol{\\gamma}_0||_{\\widehat{\\boldsymbol{W}}}^2 - \\boldsymbol{\\gamma}_0^T \\widehat{\\boldsymbol{W}} \\boldsymbol{\\gamma}_0 + 2\\widehat{\\boldsymbol{\\gamma}}^T \\widehat{\\boldsymbol{W}} \\boldsymbol{\\gamma}_0 \\\\ &amp;+ \\boldsymbol{\\gamma}(\\boldsymbol{\\theta})^T \\widehat{\\boldsymbol{W}} \\boldsymbol{\\gamma}(\\boldsymbol{\\theta}) - 2\\hat{\\boldsymbol{\\gamma}}^T\\widehat{\\boldsymbol{W}}\\boldsymbol{\\gamma}(\\boldsymbol{\\theta}) - \\boldsymbol{\\gamma}_0^T \\boldsymbol{W} \\boldsymbol{\\gamma}_0 - \\boldsymbol{\\gamma}(\\boldsymbol{\\theta})^T \\boldsymbol{W} \\boldsymbol{\\gamma}(\\boldsymbol{\\theta}) + 2\\boldsymbol{\\gamma}_0^T \\boldsymbol{W} \\boldsymbol{\\gamma}(\\boldsymbol{\\theta}) \\\\ &amp;= ||\\hat{\\boldsymbol{\\gamma}} - \\boldsymbol{\\gamma}_0||_{\\widehat{\\boldsymbol{W}}}^2 + ||\\boldsymbol{\\gamma}_0 - \\boldsymbol{\\gamma}(\\boldsymbol{\\theta})||_{\\boldsymbol{W}^*}^2 \\\\ &amp;- 2\\boldsymbol{\\gamma}_0^T\\widehat{\\boldsymbol{W}}\\boldsymbol{\\gamma}_0 - 2\\hat{\\boldsymbol{\\gamma}}^T \\widehat{\\boldsymbol{W}} \\boldsymbol{\\gamma}(\\boldsymbol{\\theta}) + 2\\boldsymbol{\\gamma}_0^T \\widehat{\\boldsymbol{W}} \\boldsymbol{\\gamma}(\\boldsymbol{\\theta}) + 2\\hat{\\boldsymbol{\\gamma}}^T \\widehat{\\boldsymbol{W}} \\boldsymbol{\\gamma}_0 \\\\ &amp;= ||\\hat{\\boldsymbol{\\gamma}} - \\boldsymbol{\\gamma}_0||_{\\widehat{\\boldsymbol{W}}}^2 + ||\\boldsymbol{\\gamma}_0 - \\boldsymbol{\\gamma}(\\boldsymbol{\\theta})||_{\\boldsymbol{W}^*}^2 + 2(\\boldsymbol{\\gamma}_0 - \\boldsymbol{\\gamma}(\\boldsymbol{\\theta}))^T \\widehat{\\boldsymbol{W}} (\\hat{\\boldsymbol{\\gamma}} - \\boldsymbol{\\gamma}_0). \\end{align*}\\] So by triangular inequality, we have \\[\\begin{align*} |\\hat{Q}_n (\\boldsymbol{\\theta}) - {Q}_0 (\\boldsymbol{\\theta})| &amp;\\leq \\left| \\underbrace{\\|\\hat{\\boldsymbol{\\gamma}} - \\boldsymbol{\\gamma}(\\boldsymbol{\\theta}_0) \\|_{\\widehat{\\boldsymbol{W}}}^2}_{\\equiv a_1} \\right| + \\left| \\underbrace{\\|\\boldsymbol{\\gamma}(\\boldsymbol{\\theta}_0) - \\boldsymbol{\\gamma} (\\boldsymbol{\\theta}) \\|_{{\\boldsymbol{W}}^*}^2}_{\\equiv a_2} \\right| \\\\ &amp;+ \\left| \\underbrace{2 \\left( \\boldsymbol{\\gamma}(\\boldsymbol{\\theta}_0) - \\boldsymbol{\\gamma} (\\boldsymbol{\\theta})\\right)^T \\widehat{\\boldsymbol{W}} \\left( \\hat{\\boldsymbol{\\gamma}} - \\boldsymbol{\\gamma}(\\boldsymbol{\\theta}_0)\\right)}_{\\equiv a_3}\\right|. \\end{align*}\\] Before continuing, suppose that \\(\\boldsymbol{x}\\) is a vector and \\(\\boldsymbol{W}\\) the above defined matrix, we have that \\(\\boldsymbol{x}^T \\boldsymbol{W} \\boldsymbol{x} \\leq \\lambda_1 ||\\boldsymbol{x}||^2\\), where \\(\\lambda_1\\) is the largest eigenvalue of \\(\\boldsymbol{W}\\). Furthermore, let us also define the Frobenius norm of a matrix as \\(||\\boldsymbol{W}|| = (\\sum_i^N \\sum_j^J w_{i,j}^2)^{\\frac{1}{2}}\\) and \\(||\\boldsymbol{W}||^2 = \\sigma_{\\text{max}} \\leq ||\\boldsymbol{W}||\\), where \\(\\sigma_{\\text{max}}\\) is the largest singular value of \\(||\\boldsymbol{W}||\\). Using those properties, we can investigate the terms in the above equation. Considering \\(a_1\\) , we have \\[\\begin{align*} a_1 &amp;\\leq ||\\boldsymbol{\\gamma}_0 - \\boldsymbol{\\gamma} (\\boldsymbol{\\theta}) ||^2 \\lambda_1 \\leq ||\\boldsymbol{\\gamma}_0 - \\boldsymbol{\\gamma} (\\boldsymbol{\\theta}) ||^2 \\|\\boldsymbol{W}^*|| \\\\ &amp;= \\sum^3_{i = 1} \\left(\\boldsymbol{\\gamma}_{0_i} - \\boldsymbol{\\gamma}_i (\\boldsymbol{\\theta})\\right)^2 \\sqrt{\\sum^3_{i = 1} \\sum^3_{j = 1} \\left(\\hat{w}_{i,j} - w_{i,j}\\right)^2} \\\\ &amp;\\leq 3 \\underset{i}{\\text{max}} \\left(\\boldsymbol{\\gamma}_{0_i} - \\boldsymbol{\\gamma}_i (\\boldsymbol{\\theta})\\right)^2 \\cdot 3 \\underset{i}{\\text{max}} \\sqrt{\\left(\\hat{w}_{i,j} - w_{i,j}\\right)^2} \\end{align*}\\] Since \\(\\underset{i}{\\text{max}} \\left(\\boldsymbol{\\gamma}_{0_i} - \\boldsymbol{\\gamma}_i (\\boldsymbol{\\theta})\\right)^2\\) is bounded by conditions C1 to C3, and \\(\\underset{i}{\\text{max}} \\sqrt{\\left(\\hat{w}_{i,j} - w_{i,j}\\right)^2} \\overset{\\mathcal{P}}{\\mapsto} 0\\) by \\(\\widehat{\\boldsymbol{W}} \\overset{\\mathcal{P}}{\\mapsto} \\boldsymbol{W}\\), we show that \\(a_1 \\overset{\\mathcal{P}}{\\mapsto} 0\\). Similarly, we can also show that \\(a_2 \\overset{\\mathcal{P}}{\\mapsto} 0\\) using the fact that he sample moments converge to the population ones. Finally, considering the previous results on \\(a_1\\) and \\(a_2\\), we can see that the last term \\(a_3\\) also tends to 0. Therefore, we can say that for all \\(\\boldsymbol{\\theta} \\in \\boldsymbol{\\Theta}\\), \\[\\begin{equation*} |\\hat{Q}_n (\\boldsymbol{\\theta}) - Q_0(\\boldsymbol{\\theta})| \\overset{\\mathcal{P}}{\\mapsto} 0. \\end{equation*}\\] \\(\\LARGE{\\bullet}\\) In general, showing that \\(\\hat{Q}_n (\\boldsymbol{\\theta}) \\overset{\\mathcal{P}}{\\mapsto} Q_0(\\boldsymbol{\\theta})\\) for all \\(\\boldsymbol{\\theta} \\in \\boldsymbol{\\Theta}\\) for every \\(\\boldsymbol{\\theta} \\in \\boldsymbol{\\Theta}\\) is generally done using the Weak Law of Large Number (i.e. Theorem 3.1). However, when \\(X_i\\) which are not iid random variables, Theorem 3.1) cannot be applied. The following theorem (taken from Proposition 7.5 of Hamilton (1994)) generalizes this result for (weak) stationary processes with absolutely summable covariance structure. Theorem 3.6 (Weak Law of Large Number for Dependent Process) Suppose \\((X_t)\\) is a (weak) stationary process with absolutely summable autocovariance structure, then \\[\\begin{equation*} \\bar{X}_T \\overset{\\mathcal{P}}{\\mapsto} \\mathbb{E}[X_t]. \\end{equation*}\\] Proof (Weak Law of Large Number for Dependent Process). Since \\(\\bar{X}_n - \\mu\\) has mean zero, its variance is \\[\\begin{equation*} \\mathbb{E}[(\\bar{X}_n - \\mu)^2] = 1/n\\sum_{h=-\\infty}^{\\infty} \\gamma(h) \\leq 1/n\\sum_{h=-\\infty}^{\\infty} |\\gamma(h)| \\leq C/n. \\end{equation*}\\] By Chebychev’s inequality, for all \\(\\epsilon &gt; 0\\), \\[\\begin{equation*} \\mathbb{P} \\left(| \\bar{X}_n - \\mu | \\geq \\epsilon \\right) \\leq \\frac{\\mathbb{E}[(\\bar{X}_n - \\mu)^2]}{\\epsilon^2} \\leq \\frac{C}{\\epsilon^2n}, \\end{equation*}\\] so that \\[\\begin{equation*} \\underset{n \\to \\infty}{\\text{lim}} \\mathbb{P} \\left(| \\bar{X}_n - \\mu | \\geq \\epsilon \\right) \\to 0, \\end{equation*}\\] which concludes the proof. Example 3.7 (Consistency of Sample Mean) Consider a stationary AR1 process and suppose we want to study whether its sample mean converges in probability to its expected value. This time we consider a non-zero mean AR1, i.e. \\[\\begin{equation*} \\left(X_t - \\mu\\right) = \\phi \\left(X_{t-1} - \\mu\\right) + Z_t, \\end{equation*}\\] where \\(\\mu = \\mathbb{E}[X_t]\\), \\(Z_t \\overset{iid}{\\sim} \\mathcal{N} (0, \\nu^2)\\) and \\(\\nu^2 &lt; \\infty\\). This process can also be written as a linear process: \\[\\begin{equation*} X_i - \\mu = \\sum_{k=0}^{\\infty}\\phi^k Z_{i-k}. \\end{equation*}\\] Since the process is stationary for \\(|\\phi| &lt; 1\\), we have \\[\\begin{equation*} \\gamma_h = \\frac{\\nu^2 \\phi^{|h|}}{1-\\phi^2}, \\end{equation*}\\] for \\(h \\in \\mathbb{Z}\\). Then we have \\[\\begin{equation*} \\sum_{h = -\\infty}^{\\infty} |\\gamma_k| = \\sum_{h = -\\infty}^{\\infty} \\frac{\\nu^2 |\\phi|^{|h|}}{1-\\phi^2} &lt; 2 \\lim_{n\\to\\infty}\\frac{\\nu^2 (1-|\\phi|^{n+1})}{(1-\\phi^2)(1-|\\phi|)} = \\frac{2\\nu^2 }{(1-\\phi^2)(1-|\\phi|)} &lt; \\infty, \\end{equation*}\\] implying that the process has an absolutely summable covariance structure. Therefore, by applying Theorem 3.6, we can verify that \\[\\begin{equation*} \\bar{X}_T = \\frac{1}{T} \\sum_{t = 1}^T \\, X_t \\overset{\\mathcal{P}}{\\mapsto} \\mathbb{E}[X_t] = \\mu. \\end{equation*}\\] \\(\\LARGE{\\bullet}\\) 3.2.4 Consistency of Sample AutoCovariance and AutoCorrelation Functions In Chapter 2, we have defined the sample autocovariance andautocorrelation functions. In the following, we will show that these estimators are both consistent. Corollary 3.1 (Consistency of Sample AutoCovariance and AutoCorrelation Functions) Let \\((X_t)\\) be such that \\((X_t)\\) is weakly stationary and \\((X_t^2)\\) has an absolutely summable covariance structure, then for all \\(|h| &lt; \\infty\\), we have \\[\\begin{align*} \\hat{\\gamma}(h) &amp;\\overset{\\mathcal{P}}{\\mapsto} \\gamma(h),\\\\ \\hat{\\rho}(h) &amp;\\overset{\\mathcal{P}}{\\mapsto} \\rho(h). \\end{align*}\\] Proof (Consistency of Sample AutoCovariance and AutoCorrelation Functions). \\((X_t^2)\\) has an absolutely summable covariance structure implies that both \\((X_t)\\) and \\((X_tX_{t-h})\\) for all \\(h \\in \\mathbb{Z}\\) have absolutely summable covariance structures. Under the conditions that \\((X_t)\\) is weakly stationary and has absolutely summable covariance structure, we have \\(\\bar{X}_T \\overset{\\mathcal{P}}{\\mapsto} \\mu\\). Let \\[\\begin{equation*} \\tilde{\\gamma}(h) = \\frac{1}{T} \\sum_{t = h+1}^{T} \\left(X_{t} - \\mu\\right) \\left(X_{t-h} - \\mu\\right). \\end{equation*}\\] Since \\((\\left(X_{t} - \\mu\\right) \\left(X_{t-h} - \\mu\\right))\\) is stationary and has absolutely summable covariance structure, we have \\(\\tilde{\\gamma}(h) \\overset{\\mathcal{P}}{\\mapsto} \\gamma(h)\\). We can also show that \\(\\sqrt{T} \\left(\\tilde{\\gamma}(h) - \\hat{\\gamma}(h) \\right) = o_p(1)\\). Therefore, we obtain \\[\\begin{equation*} \\hat{\\gamma}(h) \\overset{\\mathcal{P}}{\\mapsto} \\gamma(h). \\end{equation*}\\] Similarly, we can show that \\[\\begin{equation*} \\left( \\hat{\\gamma}(0), \\hat{\\gamma}(h) \\right)^T \\overset{\\mathcal{P}}{\\mapsto} \\left( \\gamma(0), \\gamma(h) \\right)^T. \\end{equation*}\\] Then by Theorem 3.2, we have \\[\\begin{equation*} \\hat{\\rho}(h) \\overset{\\mathcal{P}}{\\mapsto} \\rho(h), \\end{equation*}\\] which concludes the proof. 3.3 Asymptotic Normality The Central Limit Theorem (CLT) takes one step further than the Law of Large Number. It identifies the limiting distribution of the (properly scaled) sum of random variables as the normal distribution, which allows us to do the statistical inference (confidence interval and hypothesis testing). The scale will tell us how fast this approximation converges to the normal distribution. 3.3.1 CLT for iid Random Variables Theorem 3.7 (CLT for iid sequences) Suppose \\(X_i\\) are iid random variables with \\(\\mathbb{E}[X_i] = \\mu\\) and \\(\\text{Var}(X_i) = \\sigma^2 &lt; \\infty\\). Let \\(\\bar{X}_n = \\frac{1}{n} \\sum_{i = 1}^n X_i\\), then \\(\\sqrt{n}\\left(\\bar{X}_n - \\mu\\right) \\overset{\\mathcal{D}}{\\mapsto} \\mathcal{N}(0, \\sigma^2)\\). Theorem 3.8 (CLT for iid multivariate sequences) Suppose \\(\\boldsymbol{X}_i\\) are iid random vectors with \\(\\mathbb{E}[\\boldsymbol{X}_i] = \\boldsymbol{\\mu} \\in \\mathbb{R}^d\\) and \\(\\boldsymbol{\\text{Cov}}(\\boldsymbol{X}_i) = \\boldsymbol{\\Sigma} \\in \\mathbb{R}^{d \\times d}\\). Then, we have \\(\\sqrt{n}\\left(\\bar{\\boldsymbol{X}}_n - \\boldsymbol{\\mu}\\right) \\overset{\\mathcal{D}}{\\mapsto} \\mathcal{N}(\\boldsymbol{0}, \\boldsymbol{\\Sigma})\\). Theorem 3.9 (Slutsky’s Theorem) Let \\(X_n\\), \\(Y_n\\) and \\(X\\) be random variables. If \\(X_n \\overset{\\mathcal{D}}{\\mapsto} X\\) and \\(Y_n \\overset{\\mathcal{P}}{\\mapsto} c\\) for some constant \\(c\\), then \\(X_n + Y_n \\overset{\\mathcal{D}}{\\mapsto} X+c\\), \\(X_n Y_n \\overset{\\mathcal{D}}{\\mapsto} cX\\), \\(X_n / Y_n \\overset{\\mathcal{D}}{\\mapsto} X/c\\) if \\(c \\neq 0\\). General results on the asymptotic normality of extremum estimators can be found in W. K. Newey and McFadden (1994). In this section, we will only restrict our attention to a simple example of GMM estimators as in Example 3.3. We will see that the asymptotic normality of extremum estimators is implied by combining the following results and techniques: Consistency of \\(\\hat{\\boldsymbol{\\theta}}\\), Central Limit Theorem (see Theorem 3.8), Slutsky’s Theorem (see Theorem 3.9), Taylor expansions. Example 3.8 (An Example to Prove Asymptotic Normality of Extremum Estimators) In this example we revisit Example 3.3. So we have \\[\\begin{equation*} \\hat{\\boldsymbol{\\theta}} = \\underset{\\boldsymbol{\\theta} \\in \\boldsymbol{\\Theta}}{\\text{argmax}} \\hat{Q}_n(\\boldsymbol{\\theta}) = \\underset{\\boldsymbol{\\theta} \\in \\boldsymbol{\\Theta}}{\\text{argmax}} -||\\hat{\\boldsymbol{\\gamma}} - \\boldsymbol{\\gamma}(\\boldsymbol{\\theta}) ||_\\widehat{\\boldsymbol{W}}^2 \\end{equation*}\\] where \\[\\begin{equation*} \\hat{\\boldsymbol{\\gamma}} = \\frac{1}{n} \\sum_{i = 1}^n \\begin{bmatrix} Z_i\\\\ Z_i^2\\\\ Z_i^3\\\\ \\end{bmatrix}, \\;\\;\\;\\; \\boldsymbol{\\gamma}(\\boldsymbol{\\theta}) = \\begin{bmatrix} \\mu\\\\ \\mu^2 + \\sigma^2\\\\ \\mu^3 + 3 \\mu \\sigma^2 \\end{bmatrix}. \\end{equation*}\\] So by CLT (Theorem 3.8), we have \\[\\begin{equation*} \\sqrt{n}\\left(\\hat{\\boldsymbol{\\gamma}} - \\boldsymbol{\\gamma}(\\boldsymbol{\\theta}_0)\\right) = \\frac{1}{\\sqrt{n}} \\sum_{i = 1}^n \\begin{bmatrix} Z_i - \\mu_0\\\\ Z_i^2 - \\mu_0^2 - \\sigma_0^2\\\\ Z_i^3 - \\mu_0^3 - 3 \\mu_0 \\sigma_0^2\\\\ \\end{bmatrix} \\overset{\\mathcal{D}}{\\mapsto} \\mathcal{N}(\\boldsymbol{0}, \\boldsymbol{\\Sigma}), \\end{equation*}\\] where \\(\\boldsymbol{\\Sigma} = \\text{Cov}\\left( \\begin{bmatrix} Z_i &amp; Z_i^2&amp; Z_i^3\\\\ \\end{bmatrix}^T \\right)\\). Since \\(\\hat{\\boldsymbol{\\theta}}\\) maximizes \\(\\hat{Q}_n(\\boldsymbol{\\theta})\\), we have \\[\\begin{equation*} \\frac{\\partial \\hat{Q}_n(\\boldsymbol{\\theta})}{\\partial \\boldsymbol{\\theta}} \\bigg\\rvert_{\\boldsymbol{\\theta} = \\hat{\\boldsymbol{\\theta}}} = \\frac{\\partial}{\\partial \\boldsymbol{\\theta}} \\left(\\left( \\hat{\\boldsymbol{\\gamma}} - \\boldsymbol{\\gamma}(\\boldsymbol{\\theta}) \\right) \\right)^T \\widehat{\\boldsymbol{W}} \\left( \\hat{\\boldsymbol{\\gamma}} - \\boldsymbol{\\gamma}(\\boldsymbol{\\theta}) \\right) \\bigg\\rvert_{\\boldsymbol{\\theta} = \\hat{\\boldsymbol{\\theta}}} = \\boldsymbol{0}. \\end{equation*}\\] Using Taylor expansion for \\(\\boldsymbol{\\gamma}(\\hat{\\boldsymbol{\\theta}})\\) around the true \\(\\boldsymbol{\\theta}_0\\), we obtain \\[\\begin{equation*} \\hat{\\boldsymbol{\\gamma}} - \\boldsymbol{\\gamma}(\\hat{\\boldsymbol{\\theta}}) = \\hat{\\boldsymbol{\\gamma}} - \\boldsymbol{\\gamma}(\\boldsymbol{\\theta}_0) + \\frac{\\partial \\left( \\hat{\\boldsymbol{\\gamma}} - \\boldsymbol{\\gamma}(\\boldsymbol{\\theta}) \\right)}{\\partial \\boldsymbol{\\theta}}\\bigg\\rvert_{\\boldsymbol{\\theta} = \\boldsymbol{\\theta}_0} \\left( \\hat{\\boldsymbol{\\theta}} - \\boldsymbol{\\theta}_0 \\right) + o_p(1). \\end{equation*}\\] Under certain regularity conditions, we have (using Theorem 3.2) that \\[\\begin{equation*} \\frac{\\partial}{\\partial \\boldsymbol{\\theta}} \\left( \\hat{\\boldsymbol{\\gamma}} - \\boldsymbol{\\gamma}(\\boldsymbol{\\theta}) \\right)\\bigg\\rvert_{\\boldsymbol{\\theta} = \\hat{\\boldsymbol{\\theta}}} = - \\frac{\\partial}{\\partial \\boldsymbol{\\theta}} \\boldsymbol{\\gamma}(\\boldsymbol{\\theta}) \\bigg\\rvert_{\\boldsymbol{\\theta} = \\hat{\\boldsymbol{\\theta}}} \\overset{\\mathcal{P}}{\\mapsto} - \\frac{\\partial}{\\partial \\boldsymbol{\\theta}} \\boldsymbol{\\gamma}(\\boldsymbol{\\theta}) \\bigg\\rvert_{\\boldsymbol{\\theta} = \\boldsymbol{\\theta}_0}. \\end{equation*}\\] So under certain regularity conditions, using the above equations and Slutsky’s Theorem, we can obtain that \\[\\begin{equation*} \\sqrt{n}\\left( \\hat{\\boldsymbol{\\theta}} - \\boldsymbol{\\theta}_0 \\right) \\overset{\\mathcal{D}}{\\mapsto} \\mathcal{N}\\left(\\boldsymbol{0}, \\boldsymbol{D}^T \\boldsymbol{\\Sigma} \\boldsymbol{D}\\right), \\end{equation*}\\] where \\[\\begin{equation*} \\boldsymbol{D} = \\left[ ||\\frac{\\partial}{\\partial \\boldsymbol{\\theta}} \\left( \\boldsymbol{\\gamma}(\\boldsymbol{\\theta})\\right)||_{\\boldsymbol{W}}\\rvert_{\\boldsymbol{\\theta} = \\boldsymbol{\\theta}_0} \\right]^{-1} \\left(\\frac{\\partial}{\\partial \\boldsymbol{\\theta}} \\boldsymbol{\\gamma}(\\boldsymbol{\\theta})\\bigg\\rvert_{\\boldsymbol{\\theta} = \\boldsymbol{\\theta}_0} \\right)^T \\boldsymbol{W} \\end{equation*}\\] due to the fact that \\[\\begin{equation*} \\begin{aligned} &amp;\\sqrt{n}\\left( \\hat{\\boldsymbol{\\theta}} - \\boldsymbol{\\theta}_0 \\right) = \\overbrace{-\\left[ \\left(\\frac{\\partial}{\\partial \\boldsymbol{\\theta}} \\left( \\hat{\\boldsymbol{\\gamma}} - \\boldsymbol{\\gamma}(\\boldsymbol{\\theta}) \\right)\\bigg\\rvert_{\\boldsymbol{\\theta} = \\hat{\\boldsymbol{\\theta}}} \\right)^T \\widehat{\\boldsymbol{W}} \\left( \\frac{\\partial}{\\partial \\boldsymbol{\\theta}} \\left( \\hat{\\boldsymbol{\\gamma}} - \\boldsymbol{\\gamma}(\\boldsymbol{\\theta}) \\right)\\bigg\\rvert_{\\boldsymbol{\\theta} = \\hat{\\boldsymbol{\\theta}}} \\right) \\right]^{-1}}^{ \\overset{p}{\\to} \\left[ ||\\frac{\\partial}{\\partial \\boldsymbol{\\theta}} \\left( \\hat{\\boldsymbol{\\gamma}} - \\boldsymbol{\\gamma}(\\boldsymbol{\\theta})\\right)||_{\\boldsymbol{W}}\\rvert_{\\boldsymbol{\\theta} = \\boldsymbol{\\theta}_0} \\right]^{-1}}\\\\ &amp;\\underbrace{\\left(\\frac{\\partial}{\\partial \\boldsymbol{\\theta}} \\left( \\hat{\\boldsymbol{\\gamma}} - \\boldsymbol{\\gamma}(\\boldsymbol{\\theta}) \\right)\\bigg\\rvert_{\\boldsymbol{\\theta} = \\hat{\\boldsymbol{\\theta}}} \\right)^T \\widehat{\\boldsymbol{W}}}_{\\overset{p}{\\to} \\left(\\frac{\\partial}{\\partial \\boldsymbol{\\theta}} \\left( \\hat{\\boldsymbol{\\gamma}} - \\boldsymbol{\\gamma}(\\boldsymbol{\\theta})\\right)\\rvert_{\\boldsymbol{\\theta} = \\boldsymbol{\\theta}_0} \\right)^T \\boldsymbol{W}} \\sqrt{n} \\left( \\hat{\\boldsymbol{\\gamma}} - \\boldsymbol{\\gamma}(\\boldsymbol{\\theta}_0) \\right) + o_p(1). \\end{aligned} \\end{equation*}\\] \\(\\LARGE{\\bullet}\\) 3.3.2 CLT for Dependent Processes For a dependent process, the validity of CLT requires the process to be “mixing” or “asymptotically independent”. Suppose two events \\(G\\) and \\(H\\) are independent, then \\[|\\mathbb{P}(G \\cap H) - \\mathbb{P}(G) \\mathbb{P}(H)| = 0.\\] Based on this idea, many dependence measures have been developed. The most commonly used \\(\\alpha\\)-mixing coefficient is one of these dependence measures which can be easily verified for certain stochastic processes. Definition 3.6 (Mixing Coefficients) For a stochastic process \\(\\{ X_i \\}_{i \\in \\mathbb{Z}}\\), we define the strong- or \\(\\alpha\\)-mixing coefficients as \\[\\begin{equation*} \\alpha(t_1, t_2) = \\text{sup}\\{ |\\mathbb{P}(A \\cap B) - \\mathbb{P}(A)\\mathbb{P}(B)|: \\; A\\in\\mathcal{F}_{-\\infty}^{t_1}, B\\in\\mathcal{F}_{t_2}^{\\infty} \\}, \\end{equation*}\\] where \\(\\mathcal{F}_{-\\infty}^{t_1} = \\sigma(X_{-\\infty}, \\dots, X_{t_1})\\) and \\(\\mathcal{F}_{t_2}^{\\infty} = \\sigma(X_{t_2}, \\dots, X_{\\infty})\\) are \\(\\sigma\\)-algebras generated by corresponding random variables. Remark 3.1 (Mixing Coefficients) If the process is stationary, then \\(\\alpha(t_1, t_2) = \\alpha(t_2, t_1) = \\alpha(|t_1-t_2|) \\equiv \\alpha(\\tau)\\). If \\(\\alpha(\\tau) \\to 0\\) as \\(\\tau \\to \\infty\\), then the process is strong-mixing or \\(\\alpha\\)-mixing. Theorem 3.10 (Central Limit Theorem and Alpha-Mixing) Let \\((X_t)\\) be a strictly stationary process with \\(\\mathbb{E}[X_t] =0\\). \\(S_n \\equiv \\sum_{t=1}^{n}X_t\\) is the partial sum process with \\(\\sigma_n^2 \\equiv \\text{Var}(S_n)\\). Suppose \\((X_t)\\) is \\(\\alpha\\)-mixing, and that for \\(\\delta &gt; 0\\), we have \\[\\begin{equation*} \\mathbb{E}\\left[ |X_t|^{2+\\delta} \\right] \\leq \\infty, \\mbox{ and } \\sum_{n = 0}^{\\infty} \\alpha(n)^{\\delta/2 + \\delta} \\leq \\infty. \\end{equation*}\\] Then \\[\\begin{equation*} \\underset{n \\to \\infty}{\\text{lim}}\\frac{\\sigma_n^2}{n} = \\mathbb{E}\\left[ |X_t|^{2} \\right] + 2\\sum_{k=1}^{\\infty}\\mathbb{E}\\left[ X_1X_k \\right] \\equiv \\sigma^2. \\end{equation*}\\] If \\(\\sigma^2 &gt; 0\\), \\((X_t)\\) obeys both the Central Limit Theorem with variance \\(\\sigma^2\\), and the functional Central Limit Theorem. Remark 3.2 (Implication of Alpha-Mixing) If a process \\((X_t)\\) is \\(\\alpha\\)-mixing, then its covariance structure is absolutely summable. 3.3.3 Asymptotic Normality of Sample AutoCovariance and AutoCorrelation Functions If \\((X_t)\\) is a white noise, then \\(\\hat{\\rho}(h)\\) should be equal to 0 if \\(h \\neq 0\\). In practice, this is of course not the case due the estimation error of \\(\\hat{\\rho}(h)\\). The next result gives us a way to assess whether the data comes from a completely random series or whether correlations are statistically significant at some lags. Theorem 3.11 (Distribution of Sample ACF in iid Case) If \\((X_t)\\) is white noise (with finite variance) and \\(h = 1, ..., H\\) where \\(H\\) is fixed but arbitrary, then we have that \\[\\begin{equation*} \\sqrt{T} \\left(\\hat{\\rho}(h) - {\\rho}(h)\\right) \\overset{\\mathcal{D}}{\\mapsto} \\mathcal{N}\\left(0, 1\\right). \\end{equation*}\\] The proof of Theorem 3.11 is straightforward from the CLT and Delta method. It is therefore omitted here but can for example be found in Hamilton (1994). Theorem 3.11 implies that an approximate confidence interval for \\(\\hat{\\rho}(h)\\) (in the iid case) is given by \\[\\text{CI}({\\rho}(h), \\alpha) = \\hat{\\rho}(h) \\pm \\frac{z_{1-\\frac{\\alpha}{2}} }{\\sqrt{T}}\\] for \\(0 &lt; h &lt; k &lt; \\infty\\) and where \\(z_{1- \\frac{\\alpha}{2}} \\equiv \\boldsymbol{\\Phi}^{-1}\\left( 1- \\frac{\\alpha}{2} \\right)\\) is the \\((1- \\frac{\\alpha}{2})\\) quantile of a standard normal distribution. Typically, for \\(\\alpha = 0.05\\) one would consider the following confidence interval: \\[\\text{CI}({\\rho}(h), 0.05) = \\hat{\\rho}(h) \\pm \\frac{2}{\\sqrt{T}}.\\] References "],
["allan-variance-calibration-techniques.html", "Chapter 4 Allan Variance Calibration Techniques 4.1 Review on MLE-based Methods 4.2 An Introduction of the Allan Variance 4.3 Estimation of the Allan Variance 4.4 Allan Variance-based Estimation", " Chapter 4 Allan Variance Calibration Techniques In this chapter, we will study the Allan variance (AV) and the corresponding calibration techniques. For this purpose, this chapter is organized in the following order: Review on MLE-based methods; An introduction of Allan variance; Allan variance-based estimation. 4.1 Review on MLE-based Methods In general, inertial sensor stochastic calibration involves the estimation of the parameters of composite stochastic processes. These models are typically difficult to estimate because of their latent features. In the definition below we characterize the class of composite stochastic processes we shall consider here. Definition 4.1 (Composite Stochastic Processes for IMU Calibration) Let \\((X_t)\\) be a sum of latent independent stochastic process such that: \\((X_t)\\) is made of a sum which includes a subset or all processes in the set \\(\\{\\)QN, WN, AR1, RW, DR\\(\\}\\), where processes in the subset \\(\\{\\)QN, WN, RW, DR\\(\\}\\) can be included only up to once and process AR1 can be included \\(k\\) times (\\(0 \\leq k &lt; \\infty\\)). Let \\(\\mathcal{Q}\\) denote an arbitrary compact subset of \\(\\mathbb{R}^+\\). Then, the innovation process for processes WN, RW and AR1 have respective variances \\(\\sigma^2\\), \\(\\gamma^2\\) and \\(\\nu^2\\) such that \\(\\sigma^2, \\gamma^2 \\text{ and } \\nu^2 \\in \\mathcal{Q}\\) and processes QN and DR have \\(Q^2 \\in \\mathcal{Q}\\) and \\(|\\omega|\\in \\mathcal{Q}\\) respectively. There are three main class of estimation techniques that can be used for the estimation of the class of composite stochastic processes for IMU calibration. The methods are the following: Maximum likelihood based methods: Although these methods are optimal in theory, their applicability is extremely limited due to numerical reasons and tends to perform badly in practice. Allan variance-based methods: This class of method is the most popular approach for IMU calibration. However, they typically lead to inconsistent estimators and their finite sample performance is often much lower than GMWM-based technique. GMWM and related methods: In our (very biased) opinion, these techniques are currently the optimal choice for the estimation of the parameters of the class of processes considered in Definition 4.1. As we will see, this method is in fact a formalized version Allan variance-based methods. Maximum likelihood based approaches are generally inappropriate for the estimation of the class of processes considered in Definition 4.1. In this chapter, we shall avoid a technical discussion on likelihood based method and refer the readers to Stebler et al. (2011) and Guerrier, Molinari, and Balamuta (2016) for more details. Instead, we will consider an example to illustrate the numerical issues of this technique. Example 4.1 (MLE-based IMU calibration) Suppose we have a composite stochastic process composed of a WN and an AR1 process, i.e. \\[\\begin{equation*} \\begin{aligned} Y_t &amp;= \\phi_0 Y_{t-1} + Z_t, \\;\\;\\; Z_t \\overset{iid}{\\sim} \\mathcal{N}\\left(0, \\nu^2_0 \\right), \\\\ U_t &amp;\\overset{iid}{\\sim} \\mathcal{N}\\left(0, \\sigma^2_0 \\right), \\;\\;\\;\\; X_t = Y_t + U_t. \\end{aligned} \\end{equation*}\\] Then we want to estimate the parameter \\(\\boldsymbol{\\theta}_0 = \\left[\\phi_0 \\;\\; \\nu^2_0 \\;\\; \\sigma^2_0\\right]^T\\). Since the process is Gaussian, we have \\[\\begin{equation*} \\begin{aligned} \\mathbf{X} \\sim \\mathcal{N} \\left(\\mathbf{0}, \\boldsymbol{\\Sigma}(\\boldsymbol{\\theta}_0)\\right), \\end{aligned} \\end{equation*}\\] where \\(\\mathbf{X} \\equiv [X_1, ..., X_T]^T\\) and \\(\\boldsymbol{\\Sigma}(\\boldsymbol{\\theta}_0) \\equiv \\text{Cov}(\\mathbf{X})\\). Since \\(Y_t\\) and \\(U_t\\) are independent, we have \\[\\begin{equation*} \\boldsymbol{\\Sigma}(\\boldsymbol{\\theta}_0) = \\text{Cov}(\\mathbf{X}) = \\text{Cov}(\\mathbf{Y}) + \\text{Cov}(\\mathbf{U}) = \\frac{\\nu^2_0}{1 - \\phi_0^2} \\left[ \\phi_0^{|i-j|}\\right]_{i,j = 1, ..., T} + \\sigma^2_0 \\mathbf{I}_T, \\end{equation*}\\] where \\(\\mathbf{Y} \\equiv [Y_1, ..., Y_T]^T\\), \\(\\mathbf{U} \\equiv [U_1, ..., U_T]^T\\) and where \\(\\mathbf{I}_T\\) denotes the identity matrix of dimension \\(T\\). Note that the form of \\(\\text{Cov}(\\mathbf{Y})\\) is due to the autocovariance of an AR1 which has been discussed in Chapter 2. So we can now write the log-likelihood function of the model considered here which, up to a constant, can be expressed as \\[\\begin{equation*} \\mathcal{L}\\left(\\boldsymbol{\\theta} | \\mathbf{X} \\right) = - \\log \\left( \\det \\left( \\boldsymbol{\\Sigma}(\\boldsymbol{\\theta}) \\right)\\right) - \\mathbf{X}^T \\boldsymbol{\\Sigma}(\\boldsymbol{\\theta})^{-1} \\mathbf{X}. \\end{equation*}\\] Therefore, we can find the maximum likelihood estimator for \\(\\boldsymbol{\\theta}_0\\): \\[\\begin{equation*} \\hat{\\boldsymbol{\\theta}} = \\underset{\\boldsymbol{\\theta} \\in \\boldsymbol{\\Theta}}{\\text{argmax}} \\; \\mathcal{L}\\left(\\boldsymbol{\\theta} | \\mathbf{X} \\right) = \\underset{\\boldsymbol{\\theta} \\in \\boldsymbol{\\Theta}}{\\text{argmin}} \\; \\text{log} \\left( \\det \\left( \\boldsymbol{\\Sigma}(\\boldsymbol{\\theta}) \\right)\\right) + \\mathbf{X}^T \\boldsymbol{\\Sigma}(\\boldsymbol{\\theta})^{-1} \\mathbf{X}. \\end{equation*}\\] Unfortunately, the applicability of this estimator is essentially impossible when \\(T &gt; 10^5\\) since every evaluation of this the function \\(\\mathcal{L}\\left(\\boldsymbol{\\theta} | \\mathbf{X} \\right)\\) requires to invert a \\(T \\times T\\) matrix, which entails a considerable (and often unrealistic) computational burden. An alternative approach to compute maximum likelihood estimator for \\(\\boldsymbol{\\theta}_0\\) is based on the EM-algorithm of Dempster, Laird, and Rubin (1977). If the process \\((Y_t)\\) (or \\(U_t\\)) was observed, then we could easily estimate the parameters of our model by considering separately the likelihood of both processes. Since the composite process is a state-space model we could use the following approach: \\[\\begin{equation*} \\hat{\\boldsymbol{\\theta}} = \\underset{\\boldsymbol{\\theta} \\in \\boldsymbol{\\Theta}}{\\text{argmax}} \\; \\mathcal{L}\\left(\\boldsymbol{\\theta} | \\mathbf{X}, \\hat{\\mathbf{Y}}(\\boldsymbol{\\theta}) \\right), \\end{equation*}\\] where \\(\\hat{\\mathbf{Y}}(\\boldsymbol{\\theta})\\) denotes the estimation of \\(\\mathbf{Y}\\) (i.e. the states) based on a Kalman filter assuming \\(\\boldsymbol{\\theta}\\) to be the correct parameter vector. Unfortunately, this approach suffers from the same computational limitations as the maximum likelihood estimator approach. \\(\\LARGE{\\bullet}\\) 4.2 An Introduction of the Allan Variance 4.2.1 Definition of the Allan Variance The Allan variance (AV) is a statistical technique originally developed in the mid-1960s to study the stability of precision oscillators (see e.g. Allan 1966). It can provide information on the types and magnitude of various superimposed noise terms (i.e. composite stochastic processes). This method has been adapted to characterize the properties of a variety of devices including inertial sensors (see El-Sheimy, Hou, and Niu 2008). The AV is a measure of variability developed for long term memory processes and can in fact be interpreted as a Haar wavelet coefficient variance (see D. B. Percival and Guttorp 1994). We will discuss this connection further on. Definition 4.2 (Allan Variance) We consider the AV at dyadic scales (\\(\\tau_j\\)) starting from local averages of the process which can be denoted as \\[\\begin{equation*} \\bar{X}_{t}^{(j)} \\equiv \\frac{1}{\\tau_j} \\sum_{i = 1}^{\\tau_j} X_{t - \\tau_j + i}\\, , \\label{mean.noav} \\end{equation*}\\] where \\(\\tau_j \\equiv 2^j, \\; j \\in \\left\\{x \\in \\mathbb{N} \\, : \\; 1 \\leq x &lt; \\log_2 (T) - 1 \\right\\}\\) and therefore determines the number of consecutive observations considered for the average. Then, the AV is defined as \\[\\begin{equation*} \\text{AV}_j \\left(X_t \\right) \\equiv \\frac{1}{2} \\, \\mathbb{E}\\left[ \\left(\\bar{X}_{t}^{(j)} - \\bar{X}_{t-\\tau_j}^{(j)} \\right)^2 \\right]. \\end{equation*}\\] Remark 4.1 (Alternative scale definition) The definition of the AV is actually valid for \\(\\tau_j = \\lfloor2^j\\rfloor\\) with \\(j \\in \\left\\{x \\in \\mathbb{R} \\, : \\; 1 \\leq x &lt; \\log_2 (T) - 1 \\right\\}\\). In some case, it could be used to consider this alternative definition (see e.g. El-Sheimy, Hou, and Niu 2008) but we shall restrict ourselves here to the case where \\(j \\in \\left\\{x \\in \\mathbb{N} \\, : \\; 1 \\leq x &lt; \\log_2 (T) - 1 \\right\\}\\). Remark 4.2 (Notation of the Allan Variance) For notational simplicity, we may sometimes replace \\(\\text{AV}_j \\left(X_t \\right)\\) by simply \\(\\phi_j^2\\) when the dependence of the AV to the process \\((X_t)\\) is evident. As highlighted earlier, the AV is, among others, a widely and commonly used approach in engineering for sensor calibration as it is linked to the properties of the process \\((X_t)\\) as shown in the following lemma (see e.g. D. B. Percival and Walden 2006 for the proof). Lemma 4.1 (AV Connection to PSD) For a stationary process \\((X_t)\\) with PSD \\(S_{X}(f)\\) we have \\[\\begin{equation*} \\phi_j^2 \\equiv \\text{AV}_j \\left(X_t \\right) = 4 \\int_0^{\\infty} \\frac{\\sin^4(\\pi f \\tau_j)}{(\\pi f \\tau_j)^2} S_{X}(f) df. \\label{eq:allanvariancePSD_LInk} \\end{equation*}\\] Therefore, this result establishes a direct connection between the AV and PSD. Therefore a natural question is whether the mapping PSD \\(\\mapsto\\) AV is one-to-one. Greenhall (1998) (see Theorem 1) showed that this is actually not the case. This is illustrated in the followsing Section 4.2.2. 4.2.2 Spectral Ambiguity of the Allan Variance Consider two (independent) stochastic processes \\((X_t)\\) and \\((Y_t)\\) with respective PSD \\(S_X(f)\\) and \\(S_Y(f)\\). Suppose that \\(S_X(f) \\neq S_Y(f)\\), then the two processes will have the same AV if \\[\\begin{equation*} \\Delta \\equiv \\int_0^{\\infty} \\frac{\\sin^4(\\pi f \\tau_j)}{(\\pi f \\tau_j)^2} \\Phi(f) df = 0, \\end{equation*}\\] where \\(\\Phi(f) \\equiv S_{X}(f) - S_{Y}(f)\\). To show that it is possible that \\(\\Delta = 0\\) when \\(\\Phi(f) \\neq 0\\), we will use the following critical identity: \\[\\begin{equation*} \\sin^4(x) = \\sin^2(x) - \\frac{1}{4} \\sin^2(2x). \\end{equation*}\\] First, we note that \\(\\Delta\\) may be expressed using the above critical identity as follows: \\[\\begin{equation*} \\begin{aligned} \\Delta &amp;= \\int_{0}^{\\infty} \\frac{\\sin^4\\left(\\tau \\pi f \\right)}{\\left(\\tau \\pi f \\right)^2} \\Phi(f) df \\\\ &amp;= \\lim_{n \\rightarrow -\\infty} \\int_{2^{n}}^{\\infty} \\frac{\\sin^2\\left(\\tau \\pi f \\right) - \\frac{1}{4} \\sin^2\\left(2 \\tau \\pi f \\right) }{\\left(\\tau \\pi f \\right)^2} \\Phi(f) df . \\end{aligned} \\end{equation*}\\] Second, by the change of variable \\(u = 2f\\) in the second term, we obtain \\[\\begin{equation*} \\begin{aligned} \\Delta = \\lim_{n \\rightarrow -\\infty} &amp; \\Bigg[ \\int_{2^{n}}^{\\infty} \\frac{\\sin^2\\left(\\tau \\pi f \\right)}{\\left(\\tau \\pi f \\right)^2} \\Phi(f) df - \\frac{1}{2}\\int_{2^{n+1}}^{\\infty} \\frac{\\sin^2\\left(\\tau \\pi u \\right)}{\\left(\\tau \\pi u \\right)^2} \\Phi(f) du \\Bigg]. \\end{aligned} \\end{equation*}\\] Now suppose that \\(\\Phi(f) = 2 \\Phi(2f)\\). In this case, we have \\(\\Phi(f) = 2 \\Phi(u)\\) and therefore we obtain \\[\\begin{equation*} \\begin{aligned} \\Delta &amp;= \\lim_{n \\rightarrow -\\infty} \\int_{2^{n}}^{2^{n+1}} \\frac{\\sin^2\\left(\\tau \\pi f \\right)}{\\left(\\tau \\pi f \\right)^2} \\Phi(f) df = 0. \\end{aligned} \\end{equation*}\\] This result demonstrates that the mapping from PSD to AV is not necessarily one-to-one. Greenhall (1998) showed that in the continuous case (i.e. \\(\\tau_j \\in \\mathbb{R}\\)) \\(\\Delta = 0\\) if and only if \\(\\Phi(f) = 2 \\Phi(2f)\\). However, the ``only if’’ part of this result (while conjectured) is unknown in the discrete case. 4.2.3 Properties of the Allan Variance One reason of explaining the widespread use of the AV for sensor calibration is due to the following additivity property, which is particularly convenient to identify composite stochastic processes (see Definition 2.17). Corollary 4.1 (Additivity of the AV) Consider two (independent) stochastic processes \\((X_t)\\) and \\((Y_t)\\) with respective PSD \\(S_X(f)\\) and \\(S_Y(f)\\). Suppose that we observe the process \\(Z_t = X_t + Y_t\\). Then, we have \\[\\begin{equation*} \\text{AV}_j \\left(Z_t \\right) = \\text{AV}_j \\left(X_t \\right) + \\text{AV}_j \\left(Y_t \\right). \\end{equation*}\\] Proof (Additivity of the AV). The proof of Additivity of the AV is direct from Lemma 4.1. Indeed, since \\(S_Z(f) = S_X(f) + S_Y(f)\\), we have \\[\\begin{equation*} \\begin{aligned} \\text{AV}_j \\left(Z_t \\right) &amp;= 4 \\int_0^{\\infty} \\frac{\\sin^4(\\pi f \\tau_j)}{(\\pi f \\tau_j)^2} S_{Z}(f) df\\\\ &amp;= 4 \\int_0^{\\infty} \\frac{\\sin^4(\\pi f \\tau_j)}{(\\pi f \\tau_j)^2} S_{X}(f) df + 4 \\int_0^{\\infty} \\frac{\\sin^4(\\pi f \\tau_j)}{(\\pi f \\tau_j)^2} S_{Y}(f) df\\\\ &amp;= \\text{AV}_j \\left(X_t \\right) + \\text{AV}_j \\left(Y_t \\right). \\end{aligned} \\end{equation*}\\] Lemma 4.1 is an important result which is very convenient to determine the theoretical AV of a certain stochastic process. However, the applicability of this result is often limited since the integral defined in Section 4.2.2 can be intractable. An alternative to Lemma 4.1 has been proposed by N. F. Zhang (2008) and is far advantageous from a computational standpoint. Lemma 4.2 (AV Connection to ACF) For a stationary process \\((X_t)\\) with variance \\(\\sigma^2_X\\) and ACF \\(\\rho(h)\\) we have \\[\\begin{equation*} \\text{AV}_j \\left(X_t \\right) = \\frac{\\sigma_X^2}{\\tau_j^2} \\bigg(\\tau_j\\left[1-\\rho(\\tau_j)\\right] + \\sum_{i=1}^{\\tau_j-1} i \\left[2 \\rho(\\tau_j-i) - \\rho(i) - \\rho(2\\tau_j-i)\\right]\\bigg). \\end{equation*}\\] The proof of this result is instructive and is presented in Xu et al. (2017). Using Lemma 4.2, the exact form of the AV for different stationary processes, such as the general class of ARMA models, can be derived. Moreover, N. F. Zhang (2008) provided the theoretical AV for non-stationary processes such as the random walk and ARFIMA models for which the AV, as mentioned earlier, represents a better measure of uncertainty compared to other methods. Lemma 4.2 was extended to non-stationary processes in Xu et al. (2017). Example 4.2 (Theoretical AV of an MA(1) Process) From the autocovariance we obtain \\[\\begin{equation*} \\rho(h) = \\text{corr}\\left(X_t, X_{t-h} \\right) =\\left\\{ \\begin{array}{cl} 1 &amp;\\text{if } h = 0\\\\ \\frac{\\theta}{1 + \\theta^2} &amp;\\text{if } |h| = 1\\\\ 0 &amp;\\text{if } |h| &gt; 1.\\\\ \\end{array} \\right. \\end{equation*}\\] We can now apply the formula given in Lemma 4.2, which leads to \\[\\begin{equation*} \\begin{aligned} \\text{AV}_j \\left(X_t \\right) &amp;= \\frac{\\left(1 + \\theta^2 \\right) \\sigma^2}{\\tau_j^2} \\bigg(\\tau_j + \\sum_{i=1}^{\\tau_j-1} i \\left[2 \\rho(\\tau_j-i) - \\rho(i) - \\rho(2\\tau_j-i)\\right]\\bigg)\\\\ &amp;=\\frac{\\left(1 + \\theta^2 \\right) \\sigma^2}{\\tau_j^2} \\bigg(\\tau_j + 2 \\sum_{i=1}^{\\tau_j-1} i \\rho(\\tau_j-i) -\\sum_{i=1}^{\\tau_j-1} i \\rho(i) - \\sum_{i=1}^{\\tau_j-1} i \\rho(2\\tau_j-i)\\bigg)\\\\ &amp;=\\frac{\\left(1 + \\theta^2 \\right) \\sigma^2}{\\tau_j^2} \\left(\\tau_j + 2 (\\tau_j - 1) \\rho(1) - \\rho(1) \\right)\\\\ &amp;=\\frac{\\left(1 + \\theta^2 \\right) \\sigma^2}{\\tau_j^2} \\bigg(\\tau_j + (2\\tau_j - 3) \\frac{\\theta}{1 + \\theta^2} \\bigg). \\end{aligned} \\end{equation*}\\] \\(\\LARGE{\\bullet}\\) 4.3 Estimation of the Allan Variance Several estimators of the AV have been introduced in the literature. The most commonly used one is (probably) the Maximum-Overlapping AV (MOAV) estimator proposed by D. B. Percival and Guttorp (1994), which is defined as follows: Definition 4.3 (Maximum-Overlapping AV Estimator) The MOAV is defined as: \\[\\begin{eqnarray*} \\hat{\\phi}_j^2 \\equiv \\widehat{\\text{AV}}_j \\left(X_t \\right) = \\frac{1}{2 \\left(T - 2\\tau_j + 1\\right)} \\sum_{k = 2 \\tau_j}^{T} \\left(\\bar{X}_{k}^{(j)} - \\bar{X}_{k-\\tau_j}^{(j)} \\right)^2. \\end{eqnarray*}\\] We will now study the properties of this estimator through the following lemmas. 4.3.1 Consistency of the MOAV Estimator Lemma 4.3 (Consistency of the MOAV Estimator) Let \\((X_t)\\) be such that: \\((X_t - X_{t-1})\\) is a (strongly) stationary process, \\((X_t - X_{t-1})^2\\) has absolutely summable covariance structure, \\(\\mathbb{E}\\left[(X_t - X_{t-1})^4\\right] &lt; \\infty\\), Then, we have \\[\\widehat{\\text{AV}}_j \\left(X_t \\right) \\overset{ \\mathcal{P} }{\\longrightarrow} \\text{AV}_j \\left(X_t \\right).\\] Proof (Consistency of the MOAV Estimator). The proof of the result is direct from the theorem of Weak Law of Large Number for Dependent Process in Chapter 3. Let \\(Z_t = X_t - X_{t-1}\\), then since \\(Z_t\\) is stationary with mean zero then so is \\((X_t - X_{t-h})\\) for all \\(h \\in \\mathbb{Z}\\). This directly implies that \\(\\bar{X}_{t}^{(j)} - \\bar{X}_{t-\\tau_j}^{(j)}\\) is also stationary (since it is based on a linear combination of stationary processes) and so is \\(Y_t \\equiv (\\bar{X}_{t}^{(j)} - \\bar{X}_{t-\\tau_j}^{(j)})^2\\) (since it is based on a time invariant transformation of a stationary process). Moreover, there exist constants \\(c_h\\) such that \\[\\begin{equation*} \\sum_{h = -\\infty}^{\\infty} \\; \\gamma_Y (h) = \\sum_{h = -\\infty}^{\\infty} \\; c_{|h|} \\gamma_{Z^2} (h). \\end{equation*}\\] Therefore, we obtain \\[\\begin{equation*} \\sum_{h = -\\infty}^{\\infty} \\; |\\gamma_Y (h)| = \\sum_{h = -\\infty}^{\\infty} \\; |c_{|h|} \\gamma_{Z^2} (h)| \\leq \\sup_{k = 1, ..., \\infty} c_k \\; \\sum_{h = -\\infty}^{\\infty} \\; |\\gamma_{Z^2} (h)| &lt; \\infty, \\end{equation*}\\] since both terms are bounded. Using the same approach we have that \\(\\mathbb{E}\\left[Y_t^2\\right]\\) is bounded since \\(\\mathbb{E}\\left[Z_t^4\\right]\\) is bounded. Thus, we can apply WLLN for dependent process on the process \\(Y_t\\), i.e. \\[\\begin{equation*} \\widehat{\\text{AVar}}_j \\left(X_t \\right) = \\frac{1}{2} \\bar{Z}_t \\overset{\\mathcal{P}}{\\mapsto} \\frac{1}{2} \\mathbb{E}[{Z}_t] = \\text{AVar}_j \\left(X_t \\right), \\end{equation*}\\] which concludes the proof. This result is closely related by the results of D. P. Percival (1995) on the wavelet variance. We shall explore the connection between the AV and wavelet variance later. 4.3.2 Asymptotic Normality of the MOAV Estimator Compared to consistency, the asymptotic normality of the MOAV estimator requires stronger conditions given in the following lemma. Lemma 4.4 (Asymptotic Normality of the MOAV Estimator) Let \\((X_t)\\) be such that: \\((X_t - X_{t-1})\\) is a (strongly) stationary process. \\((X_t - X_{t-1})\\) is a strong mixing process with mixing coefficient \\(\\alpha(n)\\) such that \\(\\sum_{n=1}^{\\infty} \\alpha(n)^{\\frac{\\delta}{2+\\delta}} &lt; \\infty\\) for some \\(\\delta &gt; 0\\). \\(\\mathbb{E}\\left[\\left(X_t - X_{t-1}\\right)^{4+\\delta}\\right] &lt; \\infty\\) for some \\(\\delta &gt; 0\\). Then, under these conditions we have that \\[\\sqrt{T}\\left(\\widehat{\\text{AVar}}_j \\left(X_t \\right) - \\text{AVar}_j \\left(X_t \\right) \\right) \\overset{ \\mathcal{D} }{\\longrightarrow} \\mathcal{N}(0, \\sigma^2_T/T),\\] where \\(\\sigma^2_T \\equiv \\sum_{h = -\\infty}^{\\infty}\\text{cov}\\left( \\left(\\bar{X}_{t}^{(j)} - \\bar{X}_{t-\\tau_j}^{(j)} \\right)^2, \\left(\\bar{X}_{t+h}^{(j)} - \\bar{X}_{t+h-\\tau_j}^{(j)} \\right)^2 \\right)\\). Proof (Asymptotic Normality of the MOAV Estimator). The proof of the result is direct from the Central Limit Theorem for \\(\\alpha\\)-mixing process in Chapter 3. Let \\(Z_t = X_t - X_{t-1}\\), then since \\(Z_t\\) is stationary with mean zero, then so is \\((X_t - X_{t-h})\\) for all \\(h \\in \\mathbb{Z}\\). This directly implies that \\(\\bar{X}_{t}^{(j)} - \\bar{X}_{t-\\tau_j}^{(j)}\\) is also stationary (since it is based on a linear combination of stationary processes) and so is \\(Y_t \\equiv (\\bar{X}_{t}^{(j)} - \\bar{X}_{t-\\tau_j}^{(j)})^2\\) (since it is based on a time invariant transformation of a stationary process). And since \\((Y_t)\\) is a borel-measurable function of \\(Z_t\\), we have \\((Y_t)\\) is also a strong mixing process with mixing coefficient \\(\\alpha^{\\ast}(n) \\leq \\alpha(n)\\), hence \\(\\sum_{n=1}^{\\infty} \\alpha^{\\ast}(n)^{\\delta/2 + \\delta} &lt; \\infty\\) for some \\(\\delta &gt; 0\\). Moreover, since \\((\\bar{X}_{t}^{(j)} - \\bar{X}_{t-\\tau_j}^{(j)})\\) is a linear function of \\(Z_t\\), and \\(\\mathbb{E}\\left[Z_t^{4+\\delta}\\right] &lt; \\infty\\), by triangle inequality, we have \\(\\mathbb{E}\\left[(\\bar{X}_{t}^{(j)} - \\bar{X}_{t-\\tau_j}^{(j)})^{4+\\delta}\\right] &lt; \\infty\\). Thus, we can apply CLT for \\(\\alpha\\)-mixing process on \\(Y_t\\), i.e. \\[\\begin{equation*} \\sqrt{T}\\left(\\widehat{\\text{AVar}}_j \\left(X_t \\right) - \\text{AVar}_j \\left(X_t \\right) \\right) \\overset{\\mathcal{D}}{\\mapsto} \\mathcal{N}(0, \\sigma^2_T/T), \\end{equation*}\\] where \\(\\sigma^2_T \\equiv \\sum_{h = -\\infty}^{\\infty}\\text{Cov}\\left( \\left(\\bar{X}_{t}^{(j)} - \\bar{X}_{t-\\tau_j}^{(j)} \\right)^2, \\left(\\bar{X}_{t+h}^{(j)} - \\bar{X}_{t+h-\\tau_j}^{(j)} \\right)^2 \\right)\\), which concludes the proof. 4.3.3 Confidence Interval of the MOAV Estimator Based on the asymptotic normality results (Lemma ), we can construct the \\(1-\\alpha\\) confidence intervals for \\(\\widehat{\\text{AVar}}_j \\left(X_t \\right)\\) as \\[\\begin{equation*} \\text{CI}\\left(\\text{AVar}_j \\left(X_t \\right)\\right) = \\left[ \\widehat{\\text{AVar}}_j \\left(X_t \\right) \\pm z_{1 - \\frac{\\alpha}{2}} \\frac{\\sigma_{T}}{T} \\right], \\end{equation*}\\] where \\(z_{1 - \\frac{\\alpha}{2}} \\equiv \\boldsymbol{\\Phi}^{-1}\\left( 1- \\frac{\\alpha}{2} \\right)\\) is the \\((1- \\frac{\\alpha}{2})\\) quantile of a standard normal distribution. However, the so-called “Long-Run Variance” \\(\\sigma^2_{T}\\) is usually unknown. Many methods have been proposed to consistently estimate it under mild conditions (see e.g. Whitney K Newey and West 1986). Remark 4.3 Gaussian-based confidence intervals are often problematic with the AV as the lower limit of CI can very well be negative. We will discuss an alternative method to construct the CI for such statistic later. 4.4 Allan Variance-based Estimation 4.4.1 Allan Variance log-log Representation As illustrated in Lemmas 4.1 and 4.2, the AV depends on the properties of the stochastic process \\((X_t)\\). We will see that the “log-log” representation of the AV is often useful to identify various processes that may compose \\((X_t)\\). For example, let’s suppose that \\(X_t\\) is a white noise process. We showed in 4.2 that the theoretical AV of such process is given as \\[\\begin{equation*} \\phi_j^2 \\equiv \\text{AVar}_j(X_t) = \\frac{\\sigma^2}{\\tau_j}. \\end{equation*}\\] Therefore, we have that the Allan Deviation or AD (i.e. \\(\\sqrt{\\text{AVar}_j(X_t)}\\) or \\(\\phi_j\\)) is such that \\[\\begin{equation*} \\text{log}\\left( \\phi_j \\right) = \\text{log} \\left(\\sqrt{\\frac{\\sigma^2}{\\tau_j}}\\right) = \\text{log} \\left(\\sigma\\right) - \\frac{1}{2} \\text{log} (\\tau_j). \\end{equation*}\\] Thus, the log of the AD is linear in \\(\\tau_j\\) with a slope of \\(-1/2\\) and with intercept \\(\\text{log} (\\sigma)\\) as shown in the following simple simulated example. # Load packages library(av) # Package for Allan variance functions library(simts) # Package for time series simulations # Simulate white noise Xt = gen_gts(WN(sigma2 = 1), n = 10^5) # Compute Allan variance av = avar(Xt) # Allan variance log-log representation plot(av) Figure 4.1: Simulation based on a white noise process with variance as 1 and number of observations as 10^5. Suppose now that \\((X_t)\\) is a composite stochastic process composed of a WN and a RW. For simplicity, we assume that \\(X_t = Y_t + W_t\\) where \\(Y_t\\) is a WN process with variance \\(\\sigma^2\\) and \\(W_t\\) a RW with variance \\(\\gamma^2\\). We already know that \\[\\begin{equation*} \\text{log}\\left( \\text{AVar}_j(Y_t) \\right) = \\text{log} \\left(\\sigma\\right) - \\frac{1}{2} \\text{log} (\\tau_j). \\end{equation*}\\] and it can be shown (using for example Lemma 4.1) that \\[\\begin{equation*} \\text{AVar}_j(W_t) = \\frac{1}{3} \\gamma^2 \\tau_j, \\end{equation*}\\] and therefore we can obtain \\[\\begin{equation*} \\text{log}\\left( \\sqrt{\\text{AVar}_j(W_t) } \\right) = \\log \\left(\\sqrt{\\frac{1}{3} \\gamma^2 \\tau_j}\\right) = \\text{log} \\left(\\frac{1}{\\sqrt{3}} \\gamma\\right) + \\frac{1}{2} \\text{log} (\\tau_j). \\end{equation*}\\] Thus, the log of the AD of \\((Z_t)\\) is also linear in \\(\\tau_j\\) with a slope of \\(+1/2\\). By Corollary 4.1 we also have that \\[\\begin{equation*} \\text{AVar}_j(X_t) = \\text{AVar}_j(Y_t) + \\text{AVar}_j(W_t) = \\frac{\\sigma^2}{\\tau_j} + \\frac{1}{3} \\gamma^2 \\tau_j. \\end{equation*}\\] This result can be shown in the following simulated example: # Load packages library(av) library(simts) # Simulate time series Yt = gen_gts(WN(sigma2 = 10^2), n = 10^5) Zt = gen_gts(RW(gamma2 = 0.03^2), n = 10^5) Xt = Yt + Zt # Compute Allan variance av = avar(Xt) av_of_wn = av_wn(sigma2 = 10^2, n = av$clusters) av_of_rw = av_rw(omega2 = 0.03^2, n = av$clusters) # Allan variance log-log representation plot(av) Figure 4.2: Simulation based on a white noise process with variance as 10^2 and a random walk process with variance 0.03^2 and number of observations as 10^5. # lines(av$clusters, log2(av_of_wn)) # lines(av$clusters, log2(av_of_rw)) References "]
]
