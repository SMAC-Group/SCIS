<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>An Introduction to Inertial Sensors Stochastic Calibration</title>
  <meta name="description" content="TO DO">
  <meta name="generator" content="bookdown 0.7.14 and GitBook 2.6.7">

  <meta property="og:title" content="An Introduction to Inertial Sensors Stochastic Calibration" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="TO DO" />
  <meta name="github-repo" content="SMAC-Group/SCIS" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="An Introduction to Inertial Sensors Stochastic Calibration" />
  
  <meta name="twitter:description" content="TO DO" />
  

<meta name="author" content="StÃ©phane Guerrier, Roberto Molinari, Yuming Zhang, Haotian Xu, Gaetan Bakalli, Ahmed Radi and Mucyo Karemera">


<meta name="date" content="2018-07-24">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="allan-variance-calibration-techniques.html">
<link rel="next" href="extensions.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">A Minimal Book Example</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="timeseries.html"><a href="timeseries.html"><i class="fa fa-check"></i><b>2</b> Introduction to Time Series Analysis</a><ul>
<li class="chapter" data-level="2.1" data-path="timeseries.html"><a href="timeseries.html#time-series"><i class="fa fa-check"></i><b>2.1</b> Time Series</a></li>
<li class="chapter" data-level="2.2" data-path="timeseries.html"><a href="timeseries.html#dependence-within-time-series"><i class="fa fa-check"></i><b>2.2</b> Dependence within Time Series</a></li>
<li class="chapter" data-level="2.3" data-path="timeseries.html"><a href="timeseries.html#stationarity"><i class="fa fa-check"></i><b>2.3</b> Stationarity</a></li>
<li class="chapter" data-level="2.4" data-path="timeseries.html"><a href="timeseries.html#linear-processes"><i class="fa fa-check"></i><b>2.4</b> Linear Processes</a></li>
<li class="chapter" data-level="2.5" data-path="timeseries.html"><a href="timeseries.html#basic-time-series-models"><i class="fa fa-check"></i><b>2.5</b> Basic Time Series Models</a></li>
<li class="chapter" data-level="2.6" data-path="timeseries.html"><a href="timeseries.html#fundamental-representations-of-time-series"><i class="fa fa-check"></i><b>2.6</b> Fundamental Representations of Time Series</a></li>
<li class="chapter" data-level="2.7" data-path="timeseries.html"><a href="timeseries.html#estimation-problems-with-time-series"><i class="fa fa-check"></i><b>2.7</b> Estimation Problems with Time Series</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="properties-of-statistical-estimators.html"><a href="properties-of-statistical-estimators.html"><i class="fa fa-check"></i><b>3</b> Properties of Statistical Estimators</a><ul>
<li class="chapter" data-level="3.1" data-path="properties-of-statistical-estimators.html"><a href="properties-of-statistical-estimators.html#extremum-estimators"><i class="fa fa-check"></i><b>3.1</b> Extremum Estimators</a></li>
<li class="chapter" data-level="3.2" data-path="properties-of-statistical-estimators.html"><a href="properties-of-statistical-estimators.html#consistency"><i class="fa fa-check"></i><b>3.2</b> Consistency</a><ul>
<li class="chapter" data-level="3.2.1" data-path="properties-of-statistical-estimators.html"><a href="properties-of-statistical-estimators.html#consistency-of-extremum-estimators"><i class="fa fa-check"></i><b>3.2.1</b> Consistency of Extremum Estimators</a></li>
<li class="chapter" data-level="3.2.2" data-path="properties-of-statistical-estimators.html"><a href="properties-of-statistical-estimators.html#verification-of-condition-c1"><i class="fa fa-check"></i><b>3.2.2</b> Verification of Condition C1</a></li>
<li class="chapter" data-level="3.2.3" data-path="properties-of-statistical-estimators.html"><a href="properties-of-statistical-estimators.html#verification-of-condition-c4"><i class="fa fa-check"></i><b>3.2.3</b> Verification of Condition C4</a></li>
<li class="chapter" data-level="3.2.4" data-path="properties-of-statistical-estimators.html"><a href="properties-of-statistical-estimators.html#consistency-of-sample-autocovariance-and-autocorrelation-functions"><i class="fa fa-check"></i><b>3.2.4</b> Consistency of Sample AutoCovariance and AutoCorrelation Functions</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="properties-of-statistical-estimators.html"><a href="properties-of-statistical-estimators.html#asymptotic-normality"><i class="fa fa-check"></i><b>3.3</b> Asymptotic Normality</a><ul>
<li class="chapter" data-level="3.3.1" data-path="properties-of-statistical-estimators.html"><a href="properties-of-statistical-estimators.html#clt-for-iid-random-variables"><i class="fa fa-check"></i><b>3.3.1</b> CLT for iid Random Variables</a></li>
<li class="chapter" data-level="3.3.2" data-path="properties-of-statistical-estimators.html"><a href="properties-of-statistical-estimators.html#clt-for-dependent-processes"><i class="fa fa-check"></i><b>3.3.2</b> CLT for Dependent Processes</a></li>
<li class="chapter" data-level="3.3.3" data-path="properties-of-statistical-estimators.html"><a href="properties-of-statistical-estimators.html#asymptotic-normality-of-sample-autocovariance-and-autocorrelation-functions"><i class="fa fa-check"></i><b>3.3.3</b> Asymptotic Normality of Sample AutoCovariance and AutoCorrelation Functions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="allan-variance-calibration-techniques.html"><a href="allan-variance-calibration-techniques.html"><i class="fa fa-check"></i><b>4</b> Allan Variance Calibration Techniques</a><ul>
<li class="chapter" data-level="4.1" data-path="allan-variance-calibration-techniques.html"><a href="allan-variance-calibration-techniques.html#review-on-mle-based-methods"><i class="fa fa-check"></i><b>4.1</b> Review on MLE-based Methods</a></li>
<li class="chapter" data-level="4.2" data-path="allan-variance-calibration-techniques.html"><a href="allan-variance-calibration-techniques.html#an-introduction-of-the-allan-variance"><i class="fa fa-check"></i><b>4.2</b> An Introduction of the Allan Variance</a><ul>
<li class="chapter" data-level="4.2.1" data-path="allan-variance-calibration-techniques.html"><a href="allan-variance-calibration-techniques.html#definition-of-the-allan-variance"><i class="fa fa-check"></i><b>4.2.1</b> Definition of the Allan Variance</a></li>
<li class="chapter" data-level="4.2.2" data-path="allan-variance-calibration-techniques.html"><a href="allan-variance-calibration-techniques.html#spectral-ambiguity-of-the-allan-variance"><i class="fa fa-check"></i><b>4.2.2</b> Spectral Ambiguity of the Allan Variance</a></li>
<li class="chapter" data-level="4.2.3" data-path="allan-variance-calibration-techniques.html"><a href="allan-variance-calibration-techniques.html#properties-of-the-allan-variance"><i class="fa fa-check"></i><b>4.2.3</b> Properties of the Allan Variance</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="allan-variance-calibration-techniques.html"><a href="allan-variance-calibration-techniques.html#estimation-of-the-allan-variance"><i class="fa fa-check"></i><b>4.3</b> Estimation of the Allan Variance</a><ul>
<li class="chapter" data-level="4.3.1" data-path="allan-variance-calibration-techniques.html"><a href="allan-variance-calibration-techniques.html#consistency-of-the-moav-estimator"><i class="fa fa-check"></i><b>4.3.1</b> Consistency of the MOAV Estimator</a></li>
<li class="chapter" data-level="4.3.2" data-path="allan-variance-calibration-techniques.html"><a href="allan-variance-calibration-techniques.html#asymptotic-normality-of-the-moav-estimator"><i class="fa fa-check"></i><b>4.3.2</b> Asymptotic Normality of the MOAV Estimator</a></li>
<li class="chapter" data-level="4.3.3" data-path="allan-variance-calibration-techniques.html"><a href="allan-variance-calibration-techniques.html#confidence-interval-of-the-moav-estimator"><i class="fa fa-check"></i><b>4.3.3</b> Confidence Interval of the MOAV Estimator</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="allan-variance-calibration-techniques.html"><a href="allan-variance-calibration-techniques.html#allan-variance-based-estimation"><i class="fa fa-check"></i><b>4.4</b> Allan Variance-based Estimation</a><ul>
<li class="chapter" data-level="4.4.1" data-path="allan-variance-calibration-techniques.html"><a href="allan-variance-calibration-techniques.html#allan-variance-log-log-representation"><i class="fa fa-check"></i><b>4.4.1</b> Allan Variance log-log Representation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="the-generalized-method-of-wavelet-moments.html"><a href="the-generalized-method-of-wavelet-moments.html"><i class="fa fa-check"></i><b>5</b> The Generalized Method of Wavelet Moments</a><ul>
<li class="chapter" data-level="5.1" data-path="the-generalized-method-of-wavelet-moments.html"><a href="the-generalized-method-of-wavelet-moments.html#the-wavelet-variance"><i class="fa fa-check"></i><b>5.1</b> The Wavelet Variance</a></li>
<li class="chapter" data-level="5.2" data-path="the-generalized-method-of-wavelet-moments.html"><a href="the-generalized-method-of-wavelet-moments.html#the-gmwm"><i class="fa fa-check"></i><b>5.2</b> The GMWM</a><ul>
<li class="chapter" data-level="5.2.1" data-path="the-generalized-method-of-wavelet-moments.html"><a href="the-generalized-method-of-wavelet-moments.html#choice-of-weighting-matrix"><i class="fa fa-check"></i><b>5.2.1</b> Choice of weighting matrix</a></li>
<li class="chapter" data-level="5.2.2" data-path="the-generalized-method-of-wavelet-moments.html"><a href="the-generalized-method-of-wavelet-moments.html#consistency-1"><i class="fa fa-check"></i><b>5.2.2</b> Consistency</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="extensions.html"><a href="extensions.html"><i class="fa fa-check"></i><b>6</b> Extensions</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">An Introduction to Inertial Sensors Stochastic Calibration</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="the-generalized-method-of-wavelet-moments" class="section level1">
<h1><span class="header-section-number">Chapter 5</span> The Generalized Method of Wavelet Moments</h1>
<ul>
<li>A new framework for inertial sensor calibration.</li>
<li>It is based on the Generalized Method of Wavelet Moments (GMWM) of <span class="citation">Guerrier et al. (<a href="#ref-guerrier2013wavelet">2013</a>)</span>, which is a new statistical approach to estimate the parameters of (complex) time series models.</li>
<li>The GMWM is able to estimate efficiently time series models which are commonly used to describe the errors of inertial sensors.</li>
<li>This calibration approach provides considerable improvements (in terms of navigation performance) compared to existing methods.</li>
<li>This methodology is robust (potentially applicable for FDI purposes) and is able to automatically select a suitable model (or rank models).</li>
</ul>
<div id="the-wavelet-variance" class="section level2">
<h2><span class="header-section-number">5.1</span> The Wavelet Variance</h2>
<p>The GMWM estimator is a GMM type estimator based on a quantity called the Wavelet Variance (WV). This quantity is computed by taking the variance of the Wavelet Coefficient wich are defined as</p>

<div class="definition">
<span id="def:defWC" class="definition"><strong>Definition 5.1  (Wavelet Coefficient)  </strong></span> In a similar way to the AV, we can define the Wavelet Variance (WV) at dyadic scales (<span class="math inline">\(\tau_j\)</span>) for <span class="math inline">\(j \in \left\{x \in \mathbb{N} \, : \; 1 \leq x &lt; \log_2 (T) - 1 \right\}\)</span>. To do so, we first need to define the wavelet filters <span class="math inline">\(h_{j,l}\)</span> as ``weightsââ having the following properties
<span class="math display">\[\begin{equation*}
     \sum_{l=0}^{L_j-1} h_{j,l}=0, \,\, \sum_{l=0}^{L_1-1} h_{1,l}^2 =\frac{1}{2} \, \mathrm{and } \, \sum_{l=-\infty}^{\infty} h_{1,l}  h_{1,l+2m} = 0 ,
    \label{def:wvfilter}
\end{equation*}\]</span>
<p>where <span class="math inline">\(m \in \mathbb{N}^+\)</span>, <span class="math inline">\(L_j = (2^j-1)(L_1-1)+1\)</span> is the length of the filter at level <span class="math inline">\(j\)</span> and <span class="math inline">\(L_1\)</span> is the length of the first level filter <span class="math inline">\(h_{1,l}\)</span>.\[0.2cm]</p>
<p>Then, the wavelet coefficients <span class="math inline">\(W_{j,t}\)</span> are defined as</p>
<span class="math display">\[\begin{equation*}
    W_{j,t} = \sum_{l=0}^{L_j-1}h_{j,l} X_{t-l}.
\end{equation*}\]</span>
</div>

<p>There exist many type of Wavelet Filter. In this book, we will focus on the Maximum Overlap Discrete Wavelet Transform (MODWT), which is the most usefull one.</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-1"></span>
<img src="images/modwt.png" alt="MODWT Wavelet Coefficient" width="80%" />
<p class="caption">
Figure 5.1: MODWT Wavelet Coefficient
</p>
</div>
<p>The wavelet filters give non-zero weights to observations at a given lag (window sizes of length <span class="math inline">\(L_j\)</span>). Hence, there are as many WV as there are scales, and can be computed on consecutive windows, or on overlapping windows (to get <span class="math inline">\({W}_{j,t}\)</span> using <span class="math inline">\({h_j}\)</span>). Overlapping windows lead to more efficient estimators (such as the MODWT).</p>
<p>Based on the previously computed Wavelet Coefficients <span class="math display">\[W_{j,t}\]</span>, we want to compute the WV for each scale, which is defined as:</p>

<div class="definition">
<p><span id="def:defWV" class="definition"><strong>Definition 5.2  (Wavelet Variance)  </strong></span>The WV of the Wavelet Coefficient <span class="math inline">\(W_{j,t}\)</span>, is the variance of the Wavelet Coefficients at level <span class="math inline">\(j\)</span></p>
<span class="math display">\[\begin{equation*}
     \nu_{j}^2 \equiv \text{Var}[W_{j,t}].
\end{equation*}\]</span>
</div>


<div class="lemma">
<span id="lem:lemmavtowv" class="lemma"><strong>Lemma 5.1  (Relation between WV and AV)  </strong></span>One of the propreties of the WV, is its exact relationship to the AV. Indeed, when using the Haar wavelet filter, <span class="math inline">\(h_{j,l}\)</span>, <span class="math display">\[ \nu_{j}^2 = 2 \text{AVar}_j\]</span>. The proof of this proprety is given in <span class="citation">Percival and Guttorp (<a href="#ref-percival1994long">1994</a>)</span>.
</div>

<p>Based on Lemma <a href="the-generalized-method-of-wavelet-moments.html#lem:lemmavtowv">5.1</a>, it is possible to compute the theoretical WV based on their AV counterpart.</p>

<div class="example">
<span id="exm:wvtheoar1" class="example"><strong>Example 5.1  (Theoretical WV of an AR(1) process)  </strong></span>
<span class="math display">\[\begin{equation*}
                        Y_t = \phi Y_{t-1} + \varepsilon_t, \;\; \varepsilon_t \overset{iid}{\sim}  \mathcal{N}\left( 0 , \sigma^2 \right), \;\;  t = 1, ... , T
\end{equation*}\]</span>
With <span class="math inline">\(\tau_j = 2^j\)</span>, the theoretical (Haar) WV of such process is given by
<span class="math display">\[\begin{equation*}
          \nu_{j} =\frac{\left( \frac{\tau_j}{2} - 3 \phi - \frac{\tau_j \phi^2}{2} + 4\phi^{\frac{\tau_j}{2} + 1} - \phi^{\tau_j + 1} \right) \sigma^2}{\frac{\tau_j^2}{2} \left(1 - \phi \right)^2 \left(1 - \phi^2 \right)}.
\end{equation*}\]</span>
</div>

<p>Based on the analytical formula in Example <a href="#wvtheoar1"><strong>??</strong></a>, we can plot the theoretical WV of a AR1 process for various values of the parameter <span class="math inline">\(\phi\)</span>, which is illustrated in fig.</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-2"></span>
<img src="images/AR1WVtheo.pdf" alt="Theoretical WV for AR1 processes ." width="80%" />
<p class="caption">
Figure 5.2: Theoretical WV for AR1 processes .
</p>
</div>

<div class="definition">
<span id="def:defWVest" class="definition"><strong>Definition 5.3  (Wavelet Variance Estimator)  </strong></span> An unbiased estimator for the WV issued from a certain wavelet transform is given by the  (see ) %
<span class="math display">\[\begin{equation*}
    \hat{\nu}_{j}^2 = \frac{1}{M_j(T)} \sum_{t=L_j}^{T} {W}_{j,t}^2
     \end{equation*}\]</span>
<p>% where <span class="math inline">\(M_j(T) = T - L_j + 1\)</span>.</p>
</div>

<p>There exist other estimators of the WV, in particular robust estimators that perform well when the observed time series suffers from the presence of outliers or other forms of contamination. However, when the observed time series is uncontaminated, <span class="math inline">\(\hat{\nu}_{j}^2\)</span> is the most statistically efficient.</p>

<div class="lemma">
<span id="lem:lemmWVconcist" class="lemma"><strong>Lemma 5.2  (Consistency of WV estimator)  </strong></span> Let <span class="math inline">\((X_t)\)</span> be such that:

Defining <span class="math inline">\(\hat{\boldsymbol{\nu}} \equiv [\hat{\nu}_{j}^2]_{j = 1, \dots, J}\)</span>, with <span class="math inline">\(J\)</span> being a bounded quantity, then we have <span class="math display">\[\hat{\boldsymbol{\nu}} \overset{ \mathcal{P} }{\longrightarrow} \boldsymbol{\nu} \,.\]</span>
</div>


<div class="proof">
<p> <span class="proof"><em>Proof</em> (Proof of WV consistency). </span> The proof of the element-wise consistency is direct from Theorem . Let <span class="math inline">\(Z_t = X_t - X_{t-1}\)</span>, then since <span class="math inline">\(Z_t\)</span> is stationary with mean zero then so is <span class="math inline">\((X_t - X_{t-h})\)</span> for all <span class="math inline">\(h \in \mathbb{Z}\)</span>. This directly imply that for all <span class="math inline">\(j = 1, \dots, J\)</span>, <span class="math inline">\((W_{j,t})\)</span> is also stationary (since it based on a linear combination of stationary processes) and so is <span class="math inline">\(Y_t = W_{j,t}^2\)</span> (since it is based on a time invariant transformation of a stationary process). Moreover, there exist constant <span class="math inline">\(c_h\)</span> such that</p>
<span class="math display">\[\begin{equation*}
    \sum_{h = -\infty}^{\infty} \; \gamma_Y (h) = \sum_{h = -\infty}^{\infty} \; c_{|h|} \gamma_{Z^2} (h).
\end{equation*}\]</span>
<p>Therefore, we obtain</p>
<span class="math display">\[\begin{equation*}
    \sum_{h = -\infty}^{\infty} \; |\gamma_Y (h)| = \sum_{h = -\infty}^{\infty} \; |c_{|h|} \gamma_{Z^2} (h)| \leq \sup_{k = 1, ..., \infty} c_k \; \sum_{h = -\infty}^{\infty} \; |\gamma_{Z^2} (h)| &lt; \infty,
\end{equation*}\]</span>
<p>since both terms are bounded. Using the same approach we have that <span class="math inline">\(\mathbb{E}\left[Y_t^2\right]\)</span> is bounded since <span class="math inline">\(\mathbb{E}\left[Z_t^4\right]\)</span> bounded. Thus, we can apply Theorem  on the process <span class="math inline">\(Y_t\)</span>, i.e.</p>
<span class="math display">\[\begin{equation*}
    \hat{\nu}^2_j = \frac{1}{M_j(T)} \sum_{t=L_j}^{T} {W}_{j,t}^2\overset{ \mathcal{P} }{\longrightarrow}  \nu^2_j.
\end{equation*}\]</span>
<p>\end{frame}</p>
<p>\begin{frame}{Proof of Lemma } Since <span class="math display">\[\hat{\nu}^2_j \overset{ \mathcal{P} }{\longrightarrow} \nu^2_j \, ,\]</span> and given that <span class="math inline">\(J\)</span> is a bounded quantity, we have that</p>
<span class="math display">\[\begin{eqnarray*}
    \|\hat{\boldsymbol{\nu}} - \boldsymbol{\nu}\|_2 &amp;=&amp; \sum_{j=1}^J (\hat{\nu}^2_j - \nu^2_j)^2\\
    &amp;&lt;&amp; J \,\, \underset{j}{\text{max}}\, ((\hat{\nu}^2_j - \nu^2_j)^2) \, .
\end{eqnarray*}\]</span>
<p>Based on the element-wise consistency, we have that</p>
<span class="math display">\[\begin{equation*}
    J \,\, \underset{j}{\text{max}}\, ((\hat{\nu}^2_j - \nu^2_j)^2) \overset{ \mathcal{P} }{\longrightarrow} 0,
\end{equation*}\]</span>
<p>and hence</p>
<span class="math display">\[\begin{equation*}
    \|\hat{\boldsymbol{\nu}} - \boldsymbol{\nu}\|_2 \overset{ \mathcal{P} }{\longrightarrow} 0 \, .
\end{equation*}\]</span>
which concludes the proof.<span class="math inline">\(\blacksquare\)</span>
</div>

<p>Compare to consistency, asymptotic normality requires stronger conditions given in the following lemma. <span class="math inline">\(J\)</span> is also bounded.</p>

<div class="lemma">
<p><span id="lem:lemmWVasynorm" class="lemma"><strong>Lemma 5.3  (Asymptotic Normality of WV estimator)  </strong></span>Let <span class="math inline">\((X_t)\)</span> be such that:</p>
<ul>
<li><span class="math inline">\((X_t - X_{t-1})\)</span> is a (strongly) stationary process,</li>
<li><span class="math inline">\((X_t - X_{t-1})\)</span> is a strong mixing process with mixing coefficient <span class="math inline">\(\alpha(n)\)</span> such that <span class="math inline">\(\sum_{n=1}^{\infty} \alpha(n)^{\frac{\delta}{2+\delta}} &lt; \infty\)</span> for some <span class="math inline">\(\delta &gt; 0\)</span>,</li>
<li><p><span class="math inline">\(\mathbb{E}\left[(X_t - X_{t-1})^{4+2\delta}\right] &lt; \infty\)</span> for some <span class="math inline">\(\delta &gt; 0\)</span>.</p>
Then we have, <span class="math display">\[\sqrt{T}   \left(\hat{\boldsymbol{\nu}} - \boldsymbol{\nu} \right) \overset{ \mathcal{D} }{\longrightarrow} \mathcal{N}(\mathbf{0},\boldsymbol{\Sigma}),\]</span> where <span class="math inline">\(\boldsymbol{\Sigma}\)</span> is the asymptotic covariance matrix of <span class="math inline">\(\hat{\boldsymbol{\nu}}\)</span> with elements <span class="math inline">\(\sigma^2_{ij} \equiv \sum_{h = -\infty}^{\infty}\text{cov}\left(W_{i,0}W_{j,0}, W_{i,h}W_{j,h} \right)\)</span>.
</div>
</li>
</ul>

<div class="proof">
 <span class="proof"><em>Proof</em> (Proof Asymptotic Normality of WV estimator). </span> TO DO
</div>

Based on the asymptotic normality results (Lemma ), we can construct the <span class="math inline">\((1-\alpha)\)</span>-confidence intervals for <span class="math inline">\(\hat{\nu}_j\)</span> as %
<span class="math display">\[\begin{equation*}
    \text{CI}\left(\nu_j, \alpha \right) = \left[ \hat{\nu}_j \pm z_{1- \frac{\alpha}{2}} \frac{\sigma_{jj}}{T} \right],
\end{equation*}\]</span>
<p>% where <span class="math inline">\(z_{1- \frac{\alpha}{2}} \equiv \boldsymbol{\Phi}^{-1}\left( 1- \frac{\alpha}{2} \right)\)</span> is the <span class="math inline">\((1- \frac{\alpha}{2})\)</span> quantile of a standard normal distribution.\ However, the Long-Run Variance <span class="math inline">\(\sigma_{jj}\)</span> is usually known. Many methods has been proposed to consistently estimate under mild conditions (see e.g. ).\</p>
However, for finite <span class="math inline">\(T\)</span>, CI based on the asymptotic normality would be problematic, because the lower limit of CI can be negative. Alternatively, to avoid this problem, we can use following asymptotic result %
<span class="math display">\[\begin{equation*}
    \eta \frac{\hat{\nu}_j}{\nu_j} \overset{ \mathcal{D} }{\longrightarrow} \chi^2_{\eta},
\end{equation*}\]</span>
% where <span class="math inline">\(\eta\)</span> is a constant which can be estimated by <span class="math inline">\(\max\left\{\frac{M_j}{2^j}, 1\right\}\)</span>. Moreover, this method can also avoid the estimation of Long-Run Variance <span class="math inline">\(\sigma_{jj}\)</span>. Then the confidence interval is %
<span class="math display">\[\begin{equation*}
    \text{CI}\left(\nu_j, \alpha\right) = \left[ \frac{\eta\hat{\nu}_j}{F^{-1}_{\chi^2_{\eta}}(\alpha/2)}, \; \frac{\eta\hat{\nu}_j}{F^{-1}_{\chi^2_{\eta}}(1-\alpha/2)} \right].
\end{equation*}\]</span>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Load packages</span>
<span class="kw">library</span>(wv)      <span class="co"># Package for Wavelet Variance functions</span>
<span class="kw">library</span>(simts)   <span class="co"># Package for time series simulations</span>

<span class="co"># Simulate white noise</span>
Xt =<span class="st"> </span><span class="kw">gen_gts</span>(<span class="kw">WN</span>(<span class="dt">sigma2 =</span> <span class="dv">1</span>), <span class="dt">n =</span> <span class="dv">10</span><span class="op">^</span><span class="dv">5</span>)

<span class="co"># Compute the WV</span>
wv_xt =<span class="st"> </span><span class="kw">wvar</span>(Xt)

<span class="co"># WV log-log representation</span>
<span class="kw">plot</span>(wv_xt)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:exampleWVwhitenoise"></span>
<img src="scis_files/figure-html/exampleWVwhitenoise-1.png" alt="ADD A NICE CAPTION" width="624" />
<p class="caption">
Figure 5.3: ADD A NICE CAPTION
</p>
</div>
</div>
<div id="the-gmwm" class="section level2">
<h2><span class="header-section-number">5.2</span> The GMWM</h2>
<p>To recover the parameter vector <span class="math inline">\(\boldsymbol{\theta}\)</span> that from the specified model <span class="math inline">\(F_{\boldsymbol{\theta}}\)</span>, we want to exploit the unique relationship between the theoretical WV and the vector <span class="math inline">\(\boldsymbol{\theta}\)</span>.</p>
<p>In a similar way to the method based on the AV, the idea would be to find the model parameter values implied by the observed WV, i.e.</p>
<span class="math display">\[\begin{equation*}
    \hat{\boldsymbol{\theta}} = \boldsymbol{\theta}(\hat{\boldsymbol{\nu}}) ,
\end{equation*}\]</span>
<p>where <span class="math inline">\(\boldsymbol{\theta}(\boldsymbol{\nu})\)</span> is the inverse of the function <span class="math inline">\(\boldsymbol{\nu}(\boldsymbol{\theta})\)</span>.</p>

<div class="definition">
<span id="def:defgmwm" class="definition"><strong>Definition 5.4  (Generalized Method of Wavelet Moments (GMWM))  </strong></span>The GMWM estimator is obtained as follows
<span class="math display">\[\begin{equation*}
        \hat{\boldsymbol{\theta}} = \underset{\boldsymbol{\theta} \in \boldsymbol{\Theta}}{\text{argmin}} \, (\hat{\boldsymbol{\nu}} - \boldsymbol{\nu}(\boldsymbol{\theta}))^T\boldsymbol{\Omega}(\hat{\boldsymbol{\nu}} - \boldsymbol{\nu}(\boldsymbol{\theta})),
\end{equation*}\]</span>
where <span class="math inline">\(\boldsymbol{\nu}(\boldsymbol{\theta})\)</span> is the theoretical WV implied by a model with parameter vector <span class="math inline">\(\boldsymbol{\theta}\)</span> and <span class="math inline">\(\boldsymbol{\Omega}\)</span> is a positive-definite weighting matrix.
</div>

<div id="choice-of-weighting-matrix" class="section level3">
<h3><span class="header-section-number">5.2.1</span> Choice of weighting matrix</h3>
</div>
<div id="consistency-1" class="section level3">
<h3><span class="header-section-number">5.2.2</span> Consistency</h3>

</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-guerrier2013wavelet">
<p>Guerrier, S., J. Skaloud, Y. Stebler, and M.P. Victoria-Feser. 2013. âWavelet-Variance-Based Estimation for Composite Stochastic Processes.â <em>Journal of the American Statistical Association</em> 108 (503).</p>
</div>
<div id="ref-percival1994long">
<p>Percival, D. B., and P. Guttorp. 1994. âLong-memory processes, the Allan variance and wavelets.â In <em>Wavelet Analysis and Its Applications</em>, 4:325â44. Elsevier.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="allan-variance-calibration-techniques.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="extensions.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/04-gmwm.Rmd",
"text": "Edit"
},
"download": ["scis.pdf", "scis.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
